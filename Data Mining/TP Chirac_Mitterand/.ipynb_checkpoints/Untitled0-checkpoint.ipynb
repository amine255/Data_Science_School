{
 "metadata": {
  "name": "",
  "signature": "sha256:23d8b7f1d726dc83d871451414c001475b6dedc5a997efc1b6260496b8882e17"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "ghj"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#-*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "Created on Tue Sep 16 19:25:08 2014\n",
      "\n",
      "@author: arda\n",
      "\"\"\"\n",
      "import numpy as np\n",
      "from tools import *\n",
      "\n",
      "####################################################       \n",
      "#IMPORT DATA\n",
      "####################################################\n",
      "print \"Importing data...\"  \n",
      "corpus_train = \"Data/corpus.tache1.learn.utf8\"\n",
      "fname  = corpus_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Importing data...\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################       \n",
      "#DATA MUNGING\n",
      "####################################################\n",
      "print \"Munging data...\"  \n",
      "import codecs\n",
      "import re\n",
      "    \n",
      "nblignes = compteLignes(fname)\n",
      "print \"nblignes = %d\"%nblignes\n",
      "\n",
      "alltxts = []\n",
      "labs = np.ones(nblignes)\n",
      "s=codecs.open(fname, 'r','utf-8') # pour r\u00e9gler le codage\n",
      "\n",
      "cpt = 0\n",
      "for i in range(nblignes):\n",
      "    txt = s.readline()\n",
      "    #print txt\n",
      "\n",
      "    lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
      "    txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
      "\n",
      "    #assert(lab == \"C\" or lab == \"M\")\n",
      "\n",
      "    if lab.count('M') >0:\n",
      "        labs[cpt] = -1\n",
      "    alltxts.append(txt)\n",
      "\n",
      "    cpt += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Munging data...\n",
        "nblignes = 57413\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################       \n",
      "#BAG OF WORDS\n",
      "####################################################\n",
      "print \"Creating Bag of Words...\"  \n",
      "import gensim      \n",
      "from gensim import corpora\n",
      "      \n",
      "stoplist = set('le la les de des \u00e0 un une en au ne ce d l c s je tu il que qui mais quand'.split())\n",
      "stoplist.add('')\n",
      "\n",
      "## DICO\n",
      "splitters = u'; |, |\\*|\\. | |\\'|'\n",
      "\n",
      "dictionary = corpora.Dictionary(re.split(splitters, doc.lower()) for doc in alltxts)\n",
      "\n",
      "print len(dictionary)\n",
      "\n",
      "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist   if stopword in dictionary.token2id]\n",
      "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 10 ]\n",
      "dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      "dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      "\n",
      "print len(dictionary)\n",
      "\n",
      "## PROJ\n",
      "\n",
      "texts = [[word for word in re.split(splitters, document.lower()) if word not in stoplist]  for document in alltxts]\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "## exemple de doc\n",
      "# corpus[0]\n",
      "# avec les mots\n",
      "print [dictionary[i] for i,tmp in corpus[0]]\n",
      "\n",
      "# Transformation pour passer en matrice numpy\n",
      "dataSparse = gensim.matutils.corpus2csc(corpus)\n",
      "\n",
      "\n",
      "#### tfidf\n",
      "#import sklearn.feature_extraction.text as txtTools #.TfidfTransformer\n",
      "#\n",
      "#t = txtTools.TfidfTransformer()\n",
      "#t.fit(dataSparse.T)\n",
      "#data2 = t.transform(dataSparse.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating Bag of Words...\n",
        "40196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7656\n",
        "[u'chers', u'formule', u'expression', u'dis', u'agit', u'pas', u'l\\xe0', u'amis', u'diplomatique']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################################################\n",
      "#DEFINE CLASSIFIER\n",
      "#########################################################\n",
      "print \"Defining classifier\"\n",
      "\n",
      "from sklearn import svm\n",
      "#X = [[0, 0], [1, 1]]\n",
      "#y = [0, 1]\n",
      "clf = svm.SVC() # definition du classifieur\n",
      "\n",
      "print \"Training parameters\"\n",
      "clf.fit(dataSparse.T, labs) # apprentissage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Defining classifier\n",
        "Training parameters"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################################################\n",
      "#EVALUATE CROSS VALIDATION\n",
      "#########################################################\n",
      "print \"Cross Validation...\"  \n",
      "#print \"Entering CF\"\n",
      "#\n",
      "#from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "\n",
      "## usage basique: split train/test\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split( dataSparse.T, labs, test_size=0.4, random_state=0)\n",
      "\n",
      "scores = cross_validation.cross_val_score( clf, dataSparse.T, labs, cv=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################################################\n",
      "#PREDICTING\n",
      "#########################################################\n",
      "\n",
      "corpus_to_predict = \"Data/corpus.tache1.test.utf8\"\n",
      "fname =corpus_to_predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################       \n",
      "#DATA MUNGING\n",
      "####################################################\n",
      "print \"Munging data...\"  \n",
      "import codecs\n",
      "import re\n",
      "    \n",
      "nblignes = compteLignes(fname)\n",
      "print \"nblignes = %d\"%nblignes\n",
      "\n",
      "alltxts = []\n",
      "labs = np.ones(nblignes)\n",
      "s=codecs.open(fname, 'r','utf-8') # pour r\u00e9gler le codage\n",
      "\n",
      "cpt = 0\n",
      "for i in range(nblignes):\n",
      "    txt = s.readline()\n",
      "    #print txt\n",
      "\n",
      "    lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
      "    txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
      "\n",
      "    #assert(lab == \"C\" or lab == \"M\")\n",
      "\n",
      "    if lab.count('M') >0:\n",
      "        labs[cpt] = -1\n",
      "    alltxts.append(txt)\n",
      "\n",
      "    cpt += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Munging data...\n",
        "nblignes = 27162\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texts = [[word for word in re.split(splitters, document.lower()) if word not in stoplist]  for document in alltxts]\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataSparse = gensim.matutils.corpus2csc(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataSparse.T.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "(27162, 7656)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction =clf.predict(dataSparse.T)            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text_file = open(\"Output.txt\", \"w\")\n",
      "for i in range(0,prediction.shape[0]):\n",
      "    if prediction[i] == 1.0:\n",
      "        text_file.write(\"C\\n\")\n",
      "    else:\n",
      "        text_file.write(\"M\\n\")\n",
      "            \n",
      "text_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}