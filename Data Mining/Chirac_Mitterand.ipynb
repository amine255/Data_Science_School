{
 "metadata": {
  "name": "Chirac_Mitterand",
  "signature": "sha256:cb087b7f1e06d472db2557c4e880a4658a8bc2453f1c53972a3c0ab549ae2e30"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "TP1 - SENTENCE CLASSIFICATION"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import numpy as np\n",
      "import gensim      \n",
      "from gensim import corpora\n",
      "from tools import *\n",
      "import os.path\n",
      "import sklearn.feature_extraction.text as txtTools #.TfidfTransformes\n",
      "import codecs\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_parse_data(path):  \n",
      "    nblignes = compteLignes(path)\n",
      "    print \"nblignes = %d\"%nblignes\n",
      "\n",
      "    alltxts = []\n",
      "    labs = np.ones(nblignes)\n",
      "    s=codecs.open(path, 'r','utf-8') # pour r\u00e9gler le codage\n",
      "    #s=codecs.open(path, 'r','ascii') # pour r\u00e9gler le codage\n",
      "    \n",
      "    cpt = 0\n",
      "    for i in range(nblignes):\n",
      "        txt = s.readline()\n",
      "        #print txt\n",
      "\n",
      "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
      "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
      "        #print txt\n",
      "        #assert(lab == \"C\" or lab == \"M\")\n",
      "\n",
      "        if lab.count('M') >0:\n",
      "            labs[cpt] = -1\n",
      "        alltxts.append(txt)\n",
      "\n",
      "        cpt += 1\n",
      "    return alltxts,labs\n",
      "\n",
      "\n",
      "\n",
      "def create_dictionary(alltxts,labs):\n",
      "    print \"Creating Bag of Words...\"  \n",
      "    \n",
      "    \n",
      "    #stoplist = set(u'le la a dans les de des \u00e0 un une est en au ne ce d l c s je tu il que qui mais quand et pas pour vous nous'.split())\n",
      "    #stoplist = set(get_test_data(stopwords_path,\"\\r\\n\"))\n",
      "    #stoplist = set(''.split())\n",
      "    stoplist = set('le la les de des \u00e0 un une en au ne ce d l c s je tu il que qui mais quand'.split())\n",
      "    stoplist.add('')\n",
      "    \n",
      "    ## DICO\n",
      "    splitters = u'; |, |\\*|\\. | |\\'|'\n",
      "    \n",
      "    # remplacement de la ligne:\n",
      "    dictionary = corpora.Dictionary(re.split(splitters, doc.lower()) for doc in alltxts)\n",
      "\n",
      "    #liste = (re.split(splitters, doc.lower()) for doc in alltxts) # generator = pas de place en memoire\n",
      "    #dictionary = corpora.Dictionary([u\"{0}_{1}\".format(l[i],l[i+1]) for i in xrange(len(l)-1)] for l in liste) # bigrams\n",
      "    \n",
      "    print len(dictionary)\n",
      "\n",
      "    stop_ids = [dictionary.token2id[stopword] for stopword in stoplist   if stopword in dictionary.token2id]\n",
      "    once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 10]\n",
      "    dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      "    dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      "\n",
      "    print len(dictionary)\n",
      "\n",
      "    return stoplist,splitters,dictionary\n",
      "\n",
      "\n",
      "def create_corpus(stoplist,splitters,dictionary,alltxts):\n",
      "    \n",
      "    texts = [[word for word in re.split(splitters, document.lower()) if word not in stoplist]  for document in alltxts]\n",
      "    \n",
      "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "    ## exemple de doc\n",
      "    # corpus[0]\n",
      "    # avec les mots\n",
      "    #print [dictionary[i] for i,tmp in corpus[0]]\n",
      "\n",
      "    # Transformation pour passer en matrice numpy\n",
      "    dataSparse = gensim.matutils.corpus2csc(corpus)\n",
      "    dataSparse = dataSparse.T\n",
      "\n",
      "        ### tfidf\n",
      "    t = txtTools.TfidfTransformer()\n",
      "    t.fit(dataSparse.T)\n",
      "    data2 = t.transform(dataSparse.T)\n",
      "    data2 = data2.T\n",
      "\n",
      "    return dataSparse,data2\n",
      "\n",
      "\n",
      "def get_parse_data_test(path):  \n",
      "    nblignes = compteLignes(path)\n",
      "    print \"nblignes = %d\"%nblignes\n",
      "\n",
      "    alltxts = []\n",
      "    labs = np.ones(nblignes)\n",
      "    s=codecs.open(path, 'r','utf-8') # pour r\u00e9gler le codage\n",
      "    #s=codecs.open(path, 'r','iso-8859-1') # pour r\u00e9gler le codage\n",
      "\n",
      "    cpt = 0\n",
      "    for i in range(nblignes):\n",
      "        txt = s.readline()\n",
      "        #print txt\n",
      "\n",
      "        #lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
      "        #txt = re.sub(r\"<[0-9]*:[0-9]>\",\"\\\\1\",txt)\n",
      "        txt = re.sub(r\"<[0-9]*:[0-9]*>(.*)\",\"\\\\1\",txt)\n",
      "        #assert(lab == \"C\" or lab == \"M\")\n",
      "        #print txt\n",
      "        alltxts.append(txt)\n",
      "\n",
      "        cpt += 1\n",
      "    return alltxts\n",
      "\n",
      "def get_test_data(path,delimiter):\n",
      "    txt = readAFile(path)\n",
      "    return txt.split(delimiter)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#IMPORTING DATA\n",
      "\n",
      "path_train = \"/home/arda/Documents/Data_Science_School/Data Mining/TP1-Sentence_classification/Data/corpus.tache1.learn.utf8\"\n",
      "path_test = \"/home/arda/Documents/Data_Science_School/Data Mining/TP1-Sentence_classification/Data/corpus.tache1.test.utf8\"\n",
      "\n",
      "stopwords_path = \"/home/arda/Documents/Data_Science_School/Data Mining/TP1-Sentence_classification/stopword/stop-words_french_1_fr.txt\"\n",
      "\n",
      "alltxts_train,labs = get_parse_data(path_train)\n",
      "alltxts_test= get_parse_data_test(path_test)\n",
      "\n",
      "\n",
      "stoplist,splitters,dictionary = create_dictionary(alltxts_train,labs)\n",
      "dataSparse_train,data2_train = create_corpus(stoplist,splitters,dictionary,alltxts_train)\n",
      "\n",
      "dataSparse_test,data2_test = create_corpus(stoplist,splitters,dictionary,alltxts_test)\n",
      "print \"len(alltxts_test)\", len(alltxts_test)\n",
      "\n",
      "\n",
      "print \"dataSparse_train.shape :\", dataSparse_train.shape\n",
      "print \"dataSparse_test.shape :\", dataSparse_test.shape\n",
      "\n",
      "print \"data2_train.shape :\", data2_train.shape\n",
      "print \"data2_test.shape :\", data2_test.shape\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nblignes = 57413\n",
        "nblignes = 27162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating Bag of Words..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "320168"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "invalid shape",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-d32f47c253af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mstoplist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplitters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malltxts_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdataSparse_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata2_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstoplist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplitters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malltxts_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdataSparse_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata2_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstoplist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplitters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malltxts_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-2-f2a5c09fa6ab>\u001b[0m in \u001b[0;36mcreate_corpus\u001b[1;34m(stoplist, splitters, dictionary, alltxts)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# Transformation pour passer en matrice numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mdataSparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus2csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mdataSparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataSparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/gensim/matutils.pyc\u001b[0m in \u001b[0;36mcorpus2csc\u001b[1;34m(corpus, num_terms, dtype, num_docs, num_nnz, printprogress)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# Read matrix dimensions given, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m   \u001b[1;31m# spmatrix will check for errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36mset_shape\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: invalid shape"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nb_chirac = 1*(labs==1).sum()\n",
      "nb_mitterand = 1*(labs==-1).sum()\n",
      "print nb_chirac\n",
      "print nb_mitterand\n",
      "\n",
      "\n",
      "rapport = nb_chirac/nb_mitterand\n",
      "print rapport\n",
      "\n",
      "\n",
      "wheights = np.where(labs==1,1,6)\n",
      "#wheights.shape = ((len(labs),1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "49890\n",
        "7523\n",
        "6\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DEFINE CLASSIFIER\n",
      "\n",
      "\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn import tree\n",
      "\n",
      "\n",
      "#clf = svm.SVC(C=1,kernel='linear',class_weight ='auto')  # definition du classifieur\n",
      "#clf = svm.LinearSVC(C=1,class_weight='auto')  # definition du classifieur\n",
      "clf = MultinomialNB(alpha=0.5,class_prior=np.array([1,10]))\n",
      "#clf = MultinomialNB(alpha=0.5)\n",
      "#clf = linear_model.SGDClassifier()\n",
      "\n",
      "\n",
      "print \"Training parameters\"\n",
      "\n",
      "clf.fit(dataSparse_train,labs)   # apprentissage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training parameters\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "MultinomialNB(alpha=0.5, class_prior=array([ 1, 10]), fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EVALUATE CROSS VALIDATION\n",
      "\n",
      "#from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "\n",
      "## usage basique: split train/test\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split( dataSparse_train, labs, test_size=0.1, random_state=0)\n",
      "\n",
      "scores = cross_validation.cross_val_score( clf, dataSparse_train, labs, cv=10)\n",
      "scores\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "array([ 0.89829328,  0.89620341,  0.89254615,  0.90297858,  0.88172792,\n",
        "        0.89426929,  0.89392092,  0.89043721,  0.88434071,  0.88120536])"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PREDICTION\n",
      "prediction = clf.predict(dataSparse_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(prediction.shape[0]):\n",
      "    if prediction[i] == prediction[i-2] == -1:\n",
      "        prediction[i-1]=-1\n",
      "        \n",
      "for i in range(prediction.shape[0]):\n",
      "    if prediction[i] == prediction[i-2] == 1:\n",
      "        prediction[i-1]= 1\n",
      "        \n",
      "for i in range(prediction.shape[0]):\n",
      "    if prediction[i] == prediction[i-3] == -1:\n",
      "        prediction[i-1]= -1\n",
      "        prediction[i-2]= -1\n",
      "        \n",
      "for i in range(prediction.shape[0]):\n",
      "    if prediction[i] == prediction[i-3] == 1:\n",
      "        prediction[i-1]= 1\n",
      "        prediction[i-2]= 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 212,
       "text": [
        "array([ 1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
        "       -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#WRITING TO TEXTFILE\n",
      "\n",
      "text_file = open(\"sentence_prediction.txt\", \"w\")\n",
      "for i in range(0,prediction.shape[0]):\n",
      "    if prediction[i] == 1.0:\n",
      "        text_file.write(\"C\\n\")\n",
      "    else:\n",
      "        text_file.write(\"M\\n\")\n",
      "            \n",
      "text_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important = clf.feature_log_prob_\n",
      "importance1 = important[0,:]\n",
      "importance2 = important[1,:]\n",
      "\n",
      "ranking = np.chararray(((15,2)),10)\n",
      "\n",
      "for i in range(len(ranking)):\n",
      "    Mitt = dictionary[importance1.argmax()]\n",
      "    Chirac = dictionary[importance2.argmax()]\n",
      "    ranking[i,0] = Mitt\n",
      "    ranking[i,1] = Chirac\n",
      "\n",
      "    importance1[importance1.argmax()] = -100\n",
      "    importance2[importance2.argmax()] = -100\n",
      "    \n",
      "print ranking"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnicodeEncodeError",
       "evalue": "'ascii' codec can't encode character u'\\xe0' in position 0: ordinal not in range(128)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-201-3ba11b883a1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mMitt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimportance1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mChirac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimportance2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mranking\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMitt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mranking\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChirac\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xe0' in position 0: ordinal not in range(128)"
       ]
      }
     ],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# boucle explicite (pour les traitements plus complexe)\n",
      "skf = cross_validation.StratifiedKFold(labs, 2)\n",
      "for train_index, test_index in skf:\n",
      "    #train # contient les indices de train\n",
      "    #test # contient les indices de test\n",
      "    X_train, X_test = dataSparse_train[train_index], dataSparse_train[test_index]\n",
      "    y_train, y_test = labs[train_index], labs[test_index]\n",
      "    \n",
      "X_train.shape\n",
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}