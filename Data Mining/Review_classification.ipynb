{
 "metadata": {
  "name": "Review_classification",
  "signature": "sha256:73a6ea03e88cfa5944df3ac88d4c62759b791397af3dbffd474959419038df8a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import gensim      \n",
      "from gensim import corpora\n",
      "from tools import *\n",
      "import os.path\n",
      "import sklearn.feature_extraction.text as txtTools #.TfidfTransformes\n",
      "import codecs\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_from_folder(path):\n",
      "    \n",
      "    alltxts = [] # init vide\n",
      "    labs = []\n",
      "    cpt = -1\n",
      "    for cl in os.listdir(path): # parcours des fichiers d'un r\u00e9pertoire\n",
      "        print cl\n",
      "        for f in os.listdir(path+cl):\n",
      "            txt = readAFile(path+cl+'/'+f)\n",
      "            alltxts.append(txt)\n",
      "            labs.append(cpt)\n",
      "\n",
      "        cpt += 2\n",
      "    return alltxts, labs\n",
      "\n",
      "\n",
      "\n",
      "def create_dictionary(alltxts,labs):\n",
      "    print \"Creating Bag of Words...\"  \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    stoplist = set(u'a,able,out,?,even,story,-,character,see,up,:,time,characters,two,\\n,\",s,(,),movie,!,film,one,t,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'.split(\",\"))\n",
      "    #stoplist = set(u'le la a dans les de des \u00e0 un une est en au ne ce d l c s je tu il que qui mais quand et pas pour vous nous'.split())\n",
      "    #stoplist = set('one,more,even,time,much,characters,character,really,never,films,scenes,little,way,s,film,t,movie,out,story,good,two,t,up,.,;,\\,(,),*,=,&,-,:,--,\", ,?,a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'.split(','))\n",
      "    #stopwords_path =\"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/stopwords/\"\n",
      "    \n",
      "    #stoplist= get_stopwords(stopwords_path)\n",
      "    #stoplist = set(u'most,story,first,people,does,way,where,-, ,characters,them,two,see,after,had,make,plot,much,good,life,any,other,if,more,no,only,we,than,time,been,would,!,get,do,also,will,its,than,character,so,or,when,she,their,him,into,just,up,can,even,some,with,he,t,not,they,all,?,there,her,which,like,about,out,ot,what,:,(,),\",&,,the,a,and,of,to,is,in,s,as,that,it,i,on,are,his,this,for,on,by,who,hewith,film,but,one,be,an,at,was,have,has,movie,you,from'.split(','))\n",
      "    stoplist.add(u'')\n",
      "    ## DICO\n",
      "    splitters = u'; |, |\\*|\\. | |\\'|'\n",
      "   \n",
      "    # remplacement de la ligne:\n",
      "    dictionary = corpora.Dictionary(re.split(splitters, doc.lower()) for doc in alltxts)\n",
      "\n",
      "    #liste = (re.split(splitters, doc.lower()) for doc in alltxts) # generator = pas de place en memoire\n",
      "    #dictionary = corpora.Dictionary([u\"{0}_{1}\".format(l[i],l[i+1]) for i in xrange(len(l)-1)] for l in liste) # bigrams\n",
      "    \n",
      "    print len(dictionary)\n",
      "\n",
      "    stop_ids = [dictionary.token2id[stopword] for stopword in stoplist   if stopword in dictionary.token2id]\n",
      "    once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 10]\n",
      "    dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      "    dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      "\n",
      "    print len(dictionary)\n",
      "\n",
      "    return stoplist,splitters,dictionary\n",
      "\n",
      "\n",
      "def create_corpus(stoplist,splitters,dictionary,alltxts):\n",
      "    \n",
      "    texts = [[word for word in re.split(splitters, document.lower()) if word not in stoplist]  for document in alltxts]\n",
      "    \n",
      "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "    ## exemple de doc\n",
      "    # corpus[0]\n",
      "    # avec les mots\n",
      "    #print [dictionary[i] for i,tmp in corpus[0]]\n",
      "\n",
      "    # Transformation pour passer en matrice numpy\n",
      "    dataSparse = gensim.matutils.corpus2csc(corpus)\n",
      "    dataSparse = dataSparse.T\n",
      "\n",
      "        ### tfidf\n",
      "    t = txtTools.TfidfTransformer()\n",
      "    t.fit(dataSparse.T)\n",
      "    data2 = t.transform(dataSparse.T)\n",
      "    data2 = data2.T\n",
      "\n",
      "    return dataSparse,data2\n",
      "    \n",
      "    \n",
      "def get_test_data(path,delimiter):   \n",
      "    alltxts = [] # init vide\n",
      "    for cl in os.listdir(path): # parcours des fichiers d'un r\u00e9pertoire\n",
      "        print cl\n",
      "        for f in os.listdir(path+cl):\n",
      "            txt = readAFile(path+cl+'/'+f)\n",
      "            \n",
      "            alltxts += txt.split(delimiter)            \n",
      "    return alltxts\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#IMPORTING DATA\n",
      "\n",
      "path_train = \"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/data/trainset/\"\n",
      "path_test = \"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/data/testset/\"\n",
      "\n",
      "\n",
      "alltxts_train,labs = get_data_from_folder(path_train)\n",
      "alltxts_test= get_test_data(path_test,\"\\n\")\n",
      "\n",
      "\n",
      "stoplist,splitters,dictionary = create_dictionary(alltxts_train,labs)\n",
      "dataSparse_train,data2_train = create_corpus(stoplist,splitters,dictionary,alltxts_train)\n",
      "dataSparse_test,data2_test = create_corpus(stoplist,splitters,dictionary,alltxts_test)\n",
      "\n",
      "\n",
      "\n",
      "print \"dataSparse_train.shape :\", dataSparse_train.shape\n",
      "print \"dataSparse_test.shape :\", dataSparse_test.shape\n",
      "\n",
      "print \"data2_train.shape :\", data2_train.shape\n",
      "print \"data2_test.shape :\", data2_test.shape\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "neg\n",
        "pos\n",
        "test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating Bag of Words..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47169"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "dataSparse_train.shape :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000, 7969)\n",
        "dataSparse_test.shape : (25001, 7969)\n",
        "data2_train.shape : (2000, 7969)\n",
        "data2_test.shape : (25001, 7969)\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DEFINE CLASSIFIER\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn import tree\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#clf = svm.SVC(C=1,kernel='linear')  # definition du classifieur\n",
      "#clf = BernoulliNB(alpha=1)\n",
      "clf = MultinomialNB(alpha=0.5,class_prior=np.array([1,10]))\n",
      "#clf = linear_model.SGDClassifier()\n",
      "#clf = RandomForestClassifier(n_estimators=10)\n",
      "\n",
      "print \"Training parameters\"\n",
      "clf.fit(dataSparse_train,labs)   # apprentissage\n",
      "#clf.fit(data2_train,labs)   # apprentissage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training parameters\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "MultinomialNB(alpha=0.5, class_prior=array([ 1, 10]), fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EVALUATE CROSS VALIDATION\n",
      "\n",
      "#from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "\n",
      "## usage basique: split train/test\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split( dataSparse_train, labs, test_size=0.1, random_state=0)\n",
      "\n",
      "scores = cross_validation.cross_val_score( clf, dataSparse_train, labs, cv=10)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.835  0.835  0.81   0.86   0.81   0.76   0.83   0.79   0.83   0.84 ]\n"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PREDICTION\n",
      "prediction = clf.predict(dataSparse_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#WRITING TO TEXTFILE\n",
      "\n",
      "text_file = open(\"prediction\", \"w\")\n",
      "for i in range(0,prediction.shape[0]-1):\n",
      "    if prediction[i] == -1.0:\n",
      "        text_file.write(\"C\\n\")\n",
      "    else:\n",
      "        text_file.write(\"M\\n\")\n",
      "            \n",
      "text_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important = clf.feature_log_prob_\n",
      "importance1 = important[0,:]\n",
      "importance2 = important[1,:]\n",
      "\n",
      "ranking = np.chararray(((100,2)),10)\n",
      "for i in range(len(ranking)):\n",
      "    Mitt = dictionary[importance1.argmax()]\n",
      "    Chirac = dictionary[importance2.argmax()]\n",
      "    ranking[i,0] = Mitt\n",
      "    ranking[i,1] = Chirac\n",
      "\n",
      "    importance1[importance1.argmax()] = -100\n",
      "    importance2[importance2.argmax()] = -100\n",
      "    \n",
      "print ranking\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['eyes' 'lines']\n",
        " ['king' 'unfortunat']\n",
        " ['mean' 'power']\n",
        " ['basically' 'elements']\n",
        " ['side' 'cameron']\n",
        " ['hell' 'body']\n",
        " ['killed' 'taking']\n",
        " ['mission' 'brother']\n",
        " ['wouldn' 'women']\n",
        " ['room' 'lead']\n",
        " ['sequel' 'whether']\n",
        " ['predictabl' 'parents']\n",
        " ['waste' 'de']\n",
        " ['order' 'care']\n",
        " ['beginning' 'deal']\n",
        " ['annoying' 'sound']\n",
        " ['level' 'review']\n",
        " ['direction' 'feeling']\n",
        " ['godzilla' 'dog']\n",
        " ['seemed' 'romantic']\n",
        " ['mostly' 'important']\n",
        " ['white' 'murder']\n",
        " ['fails' 'team']\n",
        " ['knows' 'living']\n",
        " ['van' 'personal']\n",
        " ['dr' 'form']\n",
        " ['true' 'earth']\n",
        " ['needs' 'hit']\n",
        " ['drama' 'king']\n",
        " ['oh' 'brings']\n",
        " ['alone' 'possible']\n",
        " ['ship' 'lee']\n",
        " ['robert' 'told']\n",
        " ['late' 'meet']\n",
        " ['bunch' 'perfectly']\n",
        " ['stuff' 'easily']\n",
        " ['involving' 'result']\n",
        " ['television' 'easy']\n",
        " ['ridiculous' 'brilliant']\n",
        " ['smith' 'maybe']\n",
        " ['involved' 'sort']\n",
        " ['happen' 'already']\n",
        " ['themselves' 'happy']\n",
        " ['cool' 'note']\n",
        " ['1' 'video']\n",
        " ['lead' 'battle']\n",
        " ['west' 'usually']\n",
        " ['hours' 'close']\n",
        " ['project' 'ryan']\n",
        " ['talk' 'powerful']\n",
        " ['police' 'success']\n",
        " ['known' 'god']\n",
        " ['romantic' 'impressive']\n",
        " ['fans' 'score']\n",
        " ['murder' 'involved']\n",
        " ['couldn' 'intelligen']\n",
        " ['terrible' 'hope']\n",
        " ['close' 'involving']\n",
        " ['manages' 'released']\n",
        " ['middle' 'piece']\n",
        " ['four' 'ends']\n",
        " ['credits' 'taken']\n",
        " ['laughs' 'ben']\n",
        " ['giving' 'police']\n",
        " ['serious' 'feature']\n",
        " ['complete' 'hours']\n",
        " ['bring' 'bring']\n",
        " ['supporting' 'forced']\n",
        " ['truly' 'entertainm']\n",
        " ['fall' 'political']\n",
        " ['fine' 'fall']\n",
        " ['premise' 'leave']\n",
        " ['single' 'similar']\n",
        " ['result' 'level']\n",
        " ['figure' 'mostly']\n",
        " ['word' 'feels']\n",
        " ['dull' 'solid']\n",
        " ['girlfriend' 'quickly']\n",
        " ['god' 'events']\n",
        " ['awful' 'due']\n",
        " ['piece' 'using']\n",
        " ['crew' 'chris']\n",
        " ['classic' 'kill']\n",
        " ['suspense' 'expect']\n",
        " ['scream' 'art']\n",
        " ['dumb' 'definitely']\n",
        " ['sound' 'stop']\n",
        " ['3' 'light']\n",
        " ['theater' 'surprising']\n",
        " ['meet' 'uses']\n",
        " ['tells' 'rich']\n",
        " ['dog' 'nature']\n",
        " ['mars' 'memorable']\n",
        " ['throughout' 'visual']\n",
        " ['taking' 'number']\n",
        " ['villain' 'amazing']\n",
        " ['brothers' 'somewhat']\n",
        " ['within' 'meets']\n",
        " ['seriously' 'fans']\n",
        " ['note' 'chance']]\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "nombre = clf.feature_count_\n",
      "nombre1 = nombre[0,:]\n",
      "nombre2 = nombre[1,:]\n",
      "\n",
      "print nombre1.argmax()\n",
      "print nombre2.argmax()\n",
      "print dictionary[nombre1.argmax()]\n",
      "\n",
      "ranking1 = np.chararray(((100,2)),10)\n",
      "for i in range(len(ranking1)):\n",
      "    Mitt = dictionary[nombre1.argmax()]\n",
      "    Chirac = dictionary[nombre2.argmax()]\n",
      "    ranking1[i,0] = Mitt\n",
      "    ranking1[i,1] = Chirac\n",
      "\n",
      "    nombre1[nombre1.argmax()] = -100\n",
      "    nombre2[nombre2.argmax()] = -100\n",
      "\n",
      "ranking1\n",
      "#plt.scatter([1,2,3,4,5],nombre1[0:5])\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "0\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "chararray([['', ''],\n",
        "       ['', ''],\n",
        "       ['!', 'very'],\n",
        "       ['bad', 'life'],\n",
        "       ['plot', 'first'],\n",
        "       ['make', 'well'],\n",
        "       ['first', 'see'],\n",
        "       ['see', 'best'],\n",
        "       ['very', 'people'],\n",
        "       ['don', 'many'],\n",
        "       ['well', 'make'],\n",
        "       ['doesn', 'great'],\n",
        "       ['scene', 'man'],\n",
        "       ['people', 'being'],\n",
        "       ['here', 'new'],\n",
        "       ['know', 'scene'],\n",
        "       ['over', 'over'],\n",
        "       ['being', '!'],\n",
        "       ['action', 'such'],\n",
        "       ['man', 'love'],\n",
        "       ['director', 'world'],\n",
        "       ['re', 'movies'],\n",
        "       ['such', 'through'],\n",
        "       ['new', 'doesn'],\n",
        "       ['movies', 'still'],\n",
        "       ['another', 'plot'],\n",
        "       ['through', 'don'],\n",
        "       ['big', 'know'],\n",
        "       ['made', 'both'],\n",
        "       ['go', 'another'],\n",
        "       ['better', 'makes'],\n",
        "       ['end', 'back'],\n",
        "       ['something', 'between'],\n",
        "       ['seems', 'performanc'],\n",
        "       ['work', 'go'],\n",
        "       ['nothing', 'those'],\n",
        "       ['best', 'seen'],\n",
        "       ['life', 'here'],\n",
        "       ['isn', 'seems'],\n",
        "       ['many', 'something'],\n",
        "       ['before', 'end'],\n",
        "       ['enough', 'director'],\n",
        "       ['now', 'work'],\n",
        "       ['script', 'though'],\n",
        "       ['back', 'before'],\n",
        "       ['those', 'now'],\n",
        "       ['few', 'few'],\n",
        "       ['audience', 'although'],\n",
        "       ['around', 'made'],\n",
        "       ['going', 'role'],\n",
        "       ['think', 'years'],\n",
        "       ['still', 'take'],\n",
        "       ['love', 'same'],\n",
        "       ['thing', 'action'],\n",
        "       ['funny', 'things'],\n",
        "       ['gets', 'real'],\n",
        "       ['actually', 'right'],\n",
        "       ['look', 'john'],\n",
        "       ['makes', 'audience'],\n",
        "       ['down', 'down'],\n",
        "       ['though', 'young'],\n",
        "       ['take', 'big'],\n",
        "       ['comedy', 'around'],\n",
        "       ['last', 've'],\n",
        "       ['ve', 'family'],\n",
        "       ['real', 're'],\n",
        "       ['things', 'enough'],\n",
        "       ['between', 'gets'],\n",
        "       ['same', 'last'],\n",
        "       ['great', 'find'],\n",
        "       ['fact', 'quite'],\n",
        "       ['m', 'going'],\n",
        "       ['played', 'each'],\n",
        "       ['minutes', 'come'],\n",
        "       ['role', 'fact'],\n",
        "       ['long', 'cast'],\n",
        "       ['plays', 'played'],\n",
        "       ['point', 'actually'],\n",
        "       ['acting', 'year'],\n",
        "       ['actors', 'takes'],\n",
        "       ['seen', 'star'],\n",
        "       ['guy', 'look'],\n",
        "       ['world', 'without'],\n",
        "       ['find', 'comedy'],\n",
        "       ['come', 'think'],\n",
        "       ['cast', 'funny'],\n",
        "       ['years', 'better'],\n",
        "       ['d', 'comes'],\n",
        "       ['comes', 'plays'],\n",
        "       ['john', 'long'],\n",
        "       ['old', 'old'],\n",
        "       ['original', 'isn'],\n",
        "       ['show', 'show'],\n",
        "       ['right', 'during'],\n",
        "       ['anything', 'part'],\n",
        "       ['goes', 'himself'],\n",
        "       ['performanc', 'original'],\n",
        "       ['course', 'again'],\n",
        "       ['didn', 'always'],\n",
        "       ['interestin', 'thing']], \n",
        "      dtype='|S10')"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}