{
 "metadata": {
  "name": "",
  "signature": "sha256:f1baca40209f805f4fd8a5f0bc75787896ee3c47013fa71574b64980e8ccdc62"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import gensim      \n",
      "from gensim import corpora\n",
      "from tools import *\n",
      "import os.path\n",
      "import sklearn.feature_extraction.text as txtTools #.TfidfTransformes\n",
      "import codecs\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_from_folder(path):\n",
      "    \n",
      "    alltxts = [] # init vide\n",
      "    labs = []\n",
      "    cpt = -1\n",
      "    for cl in os.listdir(path): # parcours des fichiers d'un r\u00e9pertoire\n",
      "        print cl\n",
      "        for f in os.listdir(path+cl):\n",
      "            txt = readAFile(path+cl+'/'+f)\n",
      "            alltxts.append(txt)\n",
      "            labs.append(cpt)\n",
      "\n",
      "        cpt += 2\n",
      "    return alltxts, labs\n",
      "\n",
      "\n",
      "\n",
      "def create_dictionary(alltxts,labs):\n",
      "    print \"Creating Bag of Words...\"  \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    #stoplist = set(u'a,able,out,?,even,story,-,character,see,up,:,time,characters,two,\\n,\",s,(,),movie,!,film,one,t,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'.split(\",\"))\n",
      "    #stoplist = set(u'le la a dans les de des \u00e0 un une est en au ne ce d l c s je tu il que qui mais quand et pas pour vous nous'.split())\n",
      "    stoplist = set('one,more,even,time,much,characters,character,really,never,films,scenes,little,way,s,film,t,movie,out,story,good,two,t,up,.,;,\\,(,),*,=,&,-,:,--,\", ,?,a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'.split(','))\n",
      "    #stopwords_path =\"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/stopwords/\"\n",
      "    \n",
      "    #stoplist= get_stopwords(stopwords_path)\n",
      "    #stoplist = set(u'most,story,first,people,does,way,where,-, ,characters,them,two,see,after,had,make,plot,much,good,life,any,other,if,more,no,only,we,than,time,been,would,!,get,do,also,will,its,than,character,so,or,when,she,their,him,into,just,up,can,even,some,with,he,t,not,they,all,?,there,her,which,like,about,out,ot,what,:,(,),\",&,,the,a,and,of,to,is,in,s,as,that,it,i,on,are,his,this,for,on,by,who,hewith,film,but,one,be,an,at,was,have,has,movie,you,from'.split(','))\n",
      "    #stoplist.add(u'')\n",
      "    ## DICO\n",
      "    splitters = u'; |, |\\*|\\. | |\\'|'\n",
      "   \n",
      "    # remplacement de la ligne:\n",
      "    dictionary = corpora.Dictionary(re.split(splitters, doc.lower()) for doc in alltxts)\n",
      "\n",
      "    #liste = (re.split(splitters, doc.lower()) for doc in alltxts) # generator = pas de place en memoire\n",
      "    #dictionary = corpora.Dictionary([u\"{0}_{1}\".format(l[i],l[i+1]) for i in xrange(len(l)-1)] for l in liste) # bigrams\n",
      "    \n",
      "    print len(dictionary)\n",
      "\n",
      "    stop_ids = [dictionary.token2id[stopword] for stopword in stoplist   if stopword in dictionary.token2id]\n",
      "    once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 10]\n",
      "    dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      "    dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      "\n",
      "    print len(dictionary)\n",
      "\n",
      "    return stoplist,splitters,dictionary\n",
      "\n",
      "\n",
      "def create_corpus(stoplist,splitters,dictionary,alltxts):\n",
      "    \n",
      "    texts = [[word for word in re.split(splitters, document.lower()) if word not in stoplist]  for document in alltxts]\n",
      "    \n",
      "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "    ## exemple de doc\n",
      "    # corpus[0]\n",
      "    # avec les mots\n",
      "    #print [dictionary[i] for i,tmp in corpus[0]]\n",
      "\n",
      "    # Transformation pour passer en matrice numpy\n",
      "    dataSparse = gensim.matutils.corpus2csc(corpus)\n",
      "    dataSparse = dataSparse.T\n",
      "\n",
      "        ### tfidf\n",
      "    t = txtTools.TfidfTransformer()\n",
      "    t.fit(dataSparse.T)\n",
      "    data2 = t.transform(dataSparse.T)\n",
      "    data2 = data2.T\n",
      "\n",
      "    return dataSparse,data2\n",
      "    \n",
      "    \n",
      "def get_test_data(path,delimiter):   \n",
      "    alltxts = [] # init vide\n",
      "    for cl in os.listdir(path): # parcours des fichiers d'un r\u00e9pertoire\n",
      "        print cl\n",
      "        for f in os.listdir(path+cl):\n",
      "            txt = readAFile(path+cl+'/'+f)\n",
      "            \n",
      "            alltxts += txt.split(delimiter)            \n",
      "    return alltxts\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#IMPORTING DATA\n",
      "\n",
      "path_train = \"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/data/trainset/\"\n",
      "path_test = \"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/data/testset/\"\n",
      "\n",
      "\n",
      "alltxts_train,labs = get_data_from_folder(path_train)\n",
      "alltxts_test= get_test_data(path_test,\"\\n\")\n",
      "\n",
      "\n",
      "stoplist,splitters,dictionary = create_dictionary(alltxts_train,labs)\n",
      "dataSparse_train,data2_train = create_corpus(stoplist,splitters,dictionary,alltxts_train)\n",
      "dataSparse_test,data2_test = create_corpus(stoplist,splitters,dictionary,alltxts_test)\n",
      "\n",
      "\n",
      "\n",
      "print \"dataSparse_train.shape :\", dataSparse_train.shape\n",
      "print \"dataSparse_test.shape :\", dataSparse_test.shape\n",
      "\n",
      "print \"data2_train.shape :\", data2_train.shape\n",
      "print \"data2_test.shape :\", data2_test.shape\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "neg\n",
        "pos"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating Bag of Words..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47169"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7974"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "dataSparse_train.shape :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000, 7974)\n",
        "dataSparse_test.shape : (25001, 7974)\n",
        "data2_train.shape : (2000, 7974)\n",
        "data2_test.shape : (25001, 7974)\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DEFINE CLASSIFIER\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn import tree\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#clf = svm.SVC(C=1,kernel='linear')  # definition du classifieur\n",
      "#clf = BernoulliNB(alpha=1)\n",
      "clf = MultinomialNB(alpha=0.5,class_prior=np.array([1,10]))\n",
      "#clf = linear_model.SGDClassifier()\n",
      "#clf = RandomForestClassifier(n_estimators=10)\n",
      "\n",
      "print \"Training parameters\"\n",
      "clf.fit(dataSparse_train,labs)   # apprentissage\n",
      "#clf.fit(data2_train,labs)   # apprentissage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training parameters\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "MultinomialNB(alpha=0.5, class_prior=array([ 1, 10]), fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EVALUATE CROSS VALIDATION\n",
      "\n",
      "#from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "\n",
      "## usage basique: split train/test\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split( dataSparse_train, labs, test_size=0.1, random_state=0)\n",
      "\n",
      "scores = cross_validation.cross_val_score( clf, dataSparse_train, labs, cv=10)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.83   0.835  0.82   0.865  0.81   0.76   0.835  0.795  0.83   0.845]\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PREDICTION\n",
      "prediction = clf.predict(dataSparse_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#WRITING TO TEXTFILE\n",
      "\n",
      "text_file = open(\"prediction\", \"w\")\n",
      "for i in range(0,prediction.shape[0]-1):\n",
      "    if prediction[i] == -1.0:\n",
      "        text_file.write(\"C\\n\")\n",
      "    else:\n",
      "        text_file.write(\"M\\n\")\n",
      "            \n",
      "text_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important = clf.feature_log_prob_\n",
      "importance1 = important[0,:]\n",
      "importance2 = important[1,:]\n",
      "\n",
      "ranking = np.chararray(((100,2)),10)\n",
      "for i in range(len(ranking)):\n",
      "    Mitt = dictionary[importance1.argmax()]\n",
      "    Chirac = dictionary[importance2.argmax()]\n",
      "    ranking[i,0] = Mitt\n",
      "    ranking[i,1] = Chirac\n",
      "\n",
      "    importance1[importance1.argmax()] = -100\n",
      "    importance2[importance2.argmax()] = -100\n",
      "    \n",
      "print ranking\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['' '']\n",
        " ['' '']\n",
        " ['one' 'one']\n",
        " ['more' 'more']\n",
        " ['even' 'even']\n",
        " ['time' 'time']\n",
        " ['!' 'very']\n",
        " ['bad' 'character']\n",
        " ['much' 'much']\n",
        " ['character' 'life']\n",
        " ['plot' 'characters']\n",
        " ['characters' 'first']\n",
        " ['make' 'well']\n",
        " ['first' 'see']\n",
        " ['really' 'way']\n",
        " ['see' 'films']\n",
        " ['way' 'best']\n",
        " ['very' 'people']\n",
        " ['little' 'many']\n",
        " ['don' 'really']\n",
        " ['well' 'make']\n",
        " ['doesn' 'little']\n",
        " ['scene' 'great']\n",
        " ['people' 'man']\n",
        " ['here' 'being']\n",
        " ['never' 'new']\n",
        " ['films' 'scene']\n",
        " ['know' 'never']\n",
        " ['scenes' 'over']\n",
        " ['over' '!']\n",
        " ['being' 'such']\n",
        " ['action' 'love']\n",
        " ['man' 'world']\n",
        " ['director' 'scenes']\n",
        " ['re' 'movies']\n",
        " ['such' 'through']\n",
        " ['new' 'doesn']\n",
        " ['movies' 'still']\n",
        " ['another' 'plot']\n",
        " ['through' 'don']\n",
        " ['big' 'know']\n",
        " ['made' 'both']\n",
        " ['go' 'another']\n",
        " ['better' 'makes']\n",
        " ['end' 'back']\n",
        " ['something' 'between']\n",
        " ['seems' 'performanc']\n",
        " ['work' 'go']\n",
        " ['nothing' 'those']\n",
        " ['best' 'seen']\n",
        " ['life' 'here']\n",
        " ['isn' 'seems']\n",
        " ['many' 'something']\n",
        " ['before' 'end']\n",
        " ['enough' 'director']\n",
        " ['now' 'work']\n",
        " ['script' 'though']\n",
        " ['back' 'before']\n",
        " ['those' 'now']\n",
        " ['few' 'few']\n",
        " ['audience' 'although']\n",
        " ['around' 'made']\n",
        " ['going' 'role']\n",
        " ['think' 'years']\n",
        " ['still' 'take']\n",
        " ['love' 'same']\n",
        " ['thing' 'action']\n",
        " ['funny' 'things']\n",
        " ['gets' 'real']\n",
        " ['actually' 'right']\n",
        " ['look' 'john']\n",
        " ['makes' 'audience']\n",
        " ['down' 'down']\n",
        " ['though' 'young']\n",
        " ['take' 'big']\n",
        " ['comedy' 'around']\n",
        " ['last' 've']\n",
        " ['ve' 'family']\n",
        " ['real' 're']\n",
        " ['things' 'enough']\n",
        " ['between' 'gets']\n",
        " ['same' 'last']\n",
        " ['great' 'find']\n",
        " ['fact' 'quite']\n",
        " ['m' 'going']\n",
        " ['played' 'each']\n",
        " ['minutes' 'come']\n",
        " ['role' 'fact']\n",
        " ['long' 'cast']\n",
        " ['plays' 'played']\n",
        " ['point' 'actually']\n",
        " ['acting' 'year']\n",
        " ['actors' 'takes']\n",
        " ['seen' 'star']\n",
        " ['guy' 'look']\n",
        " ['world' 'without']\n",
        " ['find' 'comedy']\n",
        " ['come' 'think']\n",
        " ['cast' 'funny']\n",
        " ['years' 'better']]\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "nombre = clf.feature_count_\n",
      "nombre1 = nombre[0,:]\n",
      "nombre2 = nombre[1,:]\n",
      "\n",
      "print nombre1.argmax()\n",
      "print nombre2.argmax()\n",
      "print dictionary[nombre1.argmax()]\n",
      "\n",
      "ranking1 = np.chararray(((100,2)),10)\n",
      "for i in range(len(ranking1)):\n",
      "    Mitt = dictionary[nombre1.argmax()]\n",
      "    Chirac = dictionary[nombre2.argmax()]\n",
      "    ranking1[i,0] = Mitt\n",
      "    ranking1[i,1] = Chirac\n",
      "\n",
      "    nombre1[nombre1.argmax()] = -100\n",
      "    nombre2[nombre2.argmax()] = -100\n",
      "\n",
      "ranking1\n",
      "#plt.scatter([1,2,3,4,5],nombre1[0:5])\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2380\n",
        "2380\n",
        "the\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "chararray([['the', 'the'],\n",
        "       ['', ''],\n",
        "       ['and', 'and'],\n",
        "       ['of', 'of'],\n",
        "       ['to', 'to'],\n",
        "       ['is', 'is'],\n",
        "       ['in', 'in'],\n",
        "       ['\"', '\"'],\n",
        "       ['that', 'it'],\n",
        "       ['it', 'that'],\n",
        "       [')', 'as'],\n",
        "       ['(', ')'],\n",
        "       ['with', '('],\n",
        "       ['this', 'with'],\n",
        "       ['as', 'his'],\n",
        "       ['i', 'for'],\n",
        "       ['for', 'film'],\n",
        "       ['film', 'he'],\n",
        "       ['but', 'this'],\n",
        "       ['his', 'but'],\n",
        "       ['he', 'i'],\n",
        "       ['on', 'are'],\n",
        "       ['t', 'on'],\n",
        "       ['are', 'by'],\n",
        "       ['movie', 'who'],\n",
        "       ['be', 'an'],\n",
        "       ['by', 'be'],\n",
        "       ['you', 'one'],\n",
        "       ['an', 'not'],\n",
        "       ['have', 't'],\n",
        "       ['one', 'from'],\n",
        "       ['not', 'you'],\n",
        "       ['who', 'has'],\n",
        "       ['they', 'movie'],\n",
        "       ['at', 'at'],\n",
        "       ['was', 'was'],\n",
        "       ['from', 'her'],\n",
        "       ['?', 'they'],\n",
        "       ['has', 'have'],\n",
        "       ['all', 'all'],\n",
        "       ['her', 'more'],\n",
        "       ['there', 'which'],\n",
        "       ['so', 'about'],\n",
        "       ['like', 'there'],\n",
        "       ['about', 'like'],\n",
        "       ['out', 'out'],\n",
        "       ['or', 'what'],\n",
        "       ['what', 'their'],\n",
        "       ['when', 'so'],\n",
        "       ['up', 'when'],\n",
        "       ['just', 'she'],\n",
        "       ['if', '?'],\n",
        "       [':', 'up'],\n",
        "       ['some', ':'],\n",
        "       ['more', 'him'],\n",
        "       ['she', 'or'],\n",
        "       ['can', 'some'],\n",
        "       ['their', 'we'],\n",
        "       ['which', 'can'],\n",
        "       ['no', 'most'],\n",
        "       ['even', 'into'],\n",
        "       ['only', 'just'],\n",
        "       ['we', 'than'],\n",
        "       ['into', 'its'],\n",
        "       ['him', 'will'],\n",
        "       ['than', 'if'],\n",
        "       ['good', 'story'],\n",
        "       ['time', 'also'],\n",
        "       ['been', 'good'],\n",
        "       ['would', 'even'],\n",
        "       ['!', 'time'],\n",
        "       ['get', 'only'],\n",
        "       ['do', 'very'],\n",
        "       ['bad', 'character'],\n",
        "       ['much', 'other'],\n",
        "       ['its', 'no'],\n",
        "       ['will', 'much'],\n",
        "       ['character', 'would'],\n",
        "       ['them', 'life'],\n",
        "       ['most', 'characters'],\n",
        "       ['story', 'been'],\n",
        "       ['any', 'first'],\n",
        "       ['plot', 'them'],\n",
        "       ['other', 'two'],\n",
        "       ['characters', 'well'],\n",
        "       ['two', 'see'],\n",
        "       ['after', 'after'],\n",
        "       ['had', 'way'],\n",
        "       ['make', 'get'],\n",
        "       ['too', 'films'],\n",
        "       ['because', 'while'],\n",
        "       ['first', 'because'],\n",
        "       ['could', 'do'],\n",
        "       ['off', 'does'],\n",
        "       ['then', '-'],\n",
        "       ['really', 'best'],\n",
        "       ['how', 'people'],\n",
        "       ['see', 'where'],\n",
        "       ['also', 'many'],\n",
        "       ['way', 'really']], \n",
        "      dtype='|S10')"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}