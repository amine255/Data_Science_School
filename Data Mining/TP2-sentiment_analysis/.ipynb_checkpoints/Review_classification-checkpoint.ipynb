{
 "metadata": {
  "name": "",
  "signature": "sha256:2c1ff6ecee8c9831ee7da529245bb23d9b8c1b478ebfb7a45d90a03eeeb9f16d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import gensim      \n",
      "from gensim import corpora\n",
      "from tools import *\n",
      "import os.path\n",
      "import sklearn.feature_extraction.text as txtTools #.TfidfTransformes\n",
      "import codecs\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_from_folder(path):\n",
      "    \n",
      "    alltxts = [] # init vide\n",
      "    labs = []\n",
      "    cpt = -1\n",
      "    for cl in os.listdir(path): # parcours des fichiers d'un r\u00e9pertoire\n",
      "        print cl\n",
      "        for f in os.listdir(path+cl):\n",
      "            txt = readAFile(path+cl+'/'+f)\n",
      "            alltxts.append(txt)\n",
      "            labs.append(cpt)\n",
      "\n",
      "        cpt += 2\n",
      "    return alltxts, labs\n",
      "\n",
      "\n",
      "\n",
      "def create_dictionary(alltxts,labs):\n",
      "    print \"Creating Bag of Words...\"  \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    stoplist = set(u'more,good,much,first,over,--,few,a,able,out,?,even,story,-,character,see,up,:,time,characters,two,\\n,\",s,(,),movie,!,film,one,t,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'.split(\",\"))\n",
      "    #stoplist = set(u'le la a dans les de des \u00e0 un une est en au ne ce d l c s je tu il que qui mais quand et pas pour vous nous'.split())\n",
      "    #stoplist = set('one,more,even,time,much,characters,character,really,never,films,scenes,little,way,s,film,t,movie,out,story,good,two,t,up,.,;,\\,(,),*,=,&,-,:,--,\", ,?,a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'.split(','))\n",
      "    #stopwords_path =\"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/stopwords/\"\n",
      "    \n",
      "    #stoplist= get_stopwords(stopwords_path)\n",
      "    #stoplist = set(u'most,story,first,people,does,way,where,-, ,characters,them,two,see,after,had,make,plot,much,good,life,any,other,if,more,no,only,we,than,time,been,would,!,get,do,also,will,its,than,character,so,or,when,she,their,him,into,just,up,can,even,some,with,he,t,not,they,all,?,there,her,which,like,about,out,ot,what,:,(,),\",&,,the,a,and,of,to,is,in,s,as,that,it,i,on,are,his,this,for,on,by,who,hewith,film,but,one,be,an,at,was,have,has,movie,you,from'.split(','))\n",
      "    stoplist.add(u'')\n",
      "    ## DICO\n",
      "    splitters = u'; |, |\\*|\\. | |\\'|'\n",
      "   \n",
      "    # remplacement de la ligne:\n",
      "    dictionary = corpora.Dictionary(re.split(splitters, doc.lower()) for doc in alltxts)\n",
      "\n",
      "    #liste = (re.split(splitters, doc.lower()) for doc in alltxts) # generator = pas de place en memoire\n",
      "    #dictionary = corpora.Dictionary([u\"{0}_{1}\".format(l[i],l[i+1]) for i in xrange(len(l)-1)] for l in liste) # bigrams\n",
      "    \n",
      "    print len(dictionary)\n",
      "\n",
      "    stop_ids = [dictionary.token2id[stopword] for stopword in stoplist   if stopword in dictionary.token2id]\n",
      "    once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq < 10]\n",
      "    dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      "    dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      "\n",
      "    print len(dictionary)\n",
      "\n",
      "    return stoplist,splitters,dictionary\n",
      "\n",
      "\n",
      "def create_corpus(stoplist,splitters,dictionary,alltxts):\n",
      "    \n",
      "    texts = [[word for word in re.split(splitters, document.lower()) if word not in stoplist]  for document in alltxts]\n",
      "    \n",
      "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "    ## exemple de doc\n",
      "    # corpus[0]\n",
      "    # avec les mots\n",
      "    #print [dictionary[i] for i,tmp in corpus[0]]\n",
      "\n",
      "    # Transformation pour passer en matrice numpy\n",
      "    dataSparse = gensim.matutils.corpus2csc(corpus)\n",
      "    dataSparse = dataSparse.T\n",
      "\n",
      "        ### tfidf\n",
      "    t = txtTools.TfidfTransformer()\n",
      "    t.fit(dataSparse.T)\n",
      "    data2 = t.transform(dataSparse.T)\n",
      "    data2 = data2.T\n",
      "\n",
      "    return dataSparse,data2\n",
      "    \n",
      "    \n",
      "def get_test_data(path,delimiter):   \n",
      "    alltxts = [] # init vide\n",
      "    for cl in os.listdir(path): # parcours des fichiers d'un r\u00e9pertoire\n",
      "        print cl\n",
      "        for f in os.listdir(path+cl):\n",
      "            txt = readAFile(path+cl+'/'+f)\n",
      "            \n",
      "            alltxts += txt.split(delimiter)            \n",
      "    return alltxts\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#IMPORTING DATA\n",
      "\n",
      "path_train = \"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/data/trainset/\"\n",
      "path_test = \"/home/arda/Documents/Data_Science_School/Data Mining/TP2-sentiment_analysis/data/testset/\"\n",
      "\n",
      "\n",
      "alltxts_train,labs = get_data_from_folder(path_train)\n",
      "alltxts_test= get_test_data(path_test,\"\\n\")\n",
      "\n",
      "\n",
      "stoplist,splitters,dictionary = create_dictionary(alltxts_train,labs)\n",
      "dataSparse_train,data2_train = create_corpus(stoplist,splitters,dictionary,alltxts_train)\n",
      "dataSparse_test,data2_test = create_corpus(stoplist,splitters,dictionary,alltxts_test)\n",
      "\n",
      "\n",
      "\n",
      "print \"dataSparse_train.shape :\", dataSparse_train.shape\n",
      "print \"dataSparse_test.shape :\", dataSparse_test.shape\n",
      "\n",
      "print \"data2_train.shape :\", data2_train.shape\n",
      "print \"data2_test.shape :\", data2_test.shape\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "neg\n",
        "pos"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating Bag of Words..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47169"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7962"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "dataSparse_train.shape :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000, 7962)\n",
        "dataSparse_test.shape : (25001, 7962)\n",
        "data2_train.shape : (2000, 7962)\n",
        "data2_test.shape : (25001, 7962)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DEFINE CLASSIFIER\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn import tree\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#clf = svm.LinearSVC(C=0.0001,class_weight = )  # definition du classifieur\n",
      "clf = svm.LinearSVC(C=1,class_weight ='auto' )  # definition du classifieur\n",
      "#clf = BernoulliNB(alpha=1)\n",
      "#clf = MultinomialNB(alpha=0.5,class_prior=np.array([1,10]))\n",
      "#clf = linear_model.SGDClassifier()\n",
      "#clf = RandomForestClassifier(n_estimators=10)\n",
      "\n",
      "print \"Training parameters\"\n",
      "clf.fit(dataSparse_train,labs)   # apprentissage\n",
      "#clf.fit(data2_train,labs)   # apprentissage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training parameters\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "LinearSVC(C=1, class_weight='auto', dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EVALUATE CROSS VALIDATION\n",
      "\n",
      "#from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "\n",
      "## usage basique: split train/test\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split( dataSparse_train, labs, test_size=0.1, random_state=0)\n",
      "\n",
      "scores = cross_validation.cross_val_score( clf, dataSparse_train, labs, cv=10)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.83   0.83   0.835  0.855  0.875  0.81   0.825  0.825  0.86   0.85 ]\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PREDICTION\n",
      "prediction = clf.predict(dataSparse_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#WRITING TO TEXTFILE\n",
      "\n",
      "text_file = open(\"prediction\", \"w\")\n",
      "for i in range(0,prediction.shape[0]-1):\n",
      "    if prediction[i] == -1.0:\n",
      "        text_file.write(\"C\\n\")\n",
      "    else:\n",
      "        text_file.write(\"M\\n\")\n",
      "            \n",
      "text_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important = clf.coef_\n",
      "\n",
      "print important.shape\n",
      "print important[0,10]\n",
      "ranking = np.chararray( ((100,1)),10 )\n",
      "print ranking.shape[0]\n",
      "for i in range(important.shape[1]):\n",
      "    ranking[i] = dictionary[important.argmax()]\n",
      "    important[0,important.argmax()] = 0\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1, 7962)\n",
        "-0.0565941478693\n",
        "100\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "index 100 is out of bounds for axis 0 with size 100",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-96-0fd0a5f2730a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mranking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mranking\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimportant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mimportant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimportant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important = clf.feature_log_prob_\n",
      "importance1 = important[0,:]\n",
      "importance2 = important[1,:]\n",
      "\n",
      "ranking = np.chararray(((100,2)),10)\n",
      "for i in range(len(ranking)):\n",
      "    Mitt = dictionary[importance1.argmax()]\n",
      "    Chirac = dictionary[importance2.argmax()]\n",
      "    ranking[i,0] = Mitt\n",
      "    ranking[i,1] = Chirac\n",
      "\n",
      "    importance1[importance1.argmax()] = -100\n",
      "    importance2[importance2.argmax()] = -100\n",
      "    \n",
      "print ranking"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'LinearSVC' object has no attribute 'feature_log_prob_'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-56-76a8cfa605ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimportant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimportance1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimportance2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mranking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchararray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'feature_log_prob_'"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "nombre = clf.feature_count_\n",
      "nombre1 = nombre[0,:]\n",
      "nombre2 = nombre[1,:]\n",
      "\n",
      "print nombre1.argmax()\n",
      "print nombre2.argmax()\n",
      "print dictionary[nombre1.argmax()]\n",
      "\n",
      "ranking1 = np.chararray(((100,2)),10)\n",
      "for i in range(len(ranking1)):\n",
      "    Mitt = dictionary[nombre1.argmax()]\n",
      "    Chirac = dictionary[nombre2.argmax()]\n",
      "    ranking1[i,0] = Mitt\n",
      "    ranking1[i,1] = Chirac\n",
      "\n",
      "    nombre1[nombre1.argmax()] = -100\n",
      "    nombre2[nombre2.argmax()] = -100\n",
      "\n",
      "ranking1\n",
      "#plt.scatter([1,2,3,4,5],nombre1[0:5])\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "0\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "chararray([['', ''],\n",
        "       ['', ''],\n",
        "       ['!', 'very'],\n",
        "       ['bad', 'life'],\n",
        "       ['plot', 'first'],\n",
        "       ['make', 'well'],\n",
        "       ['first', 'see'],\n",
        "       ['see', 'best'],\n",
        "       ['very', 'people'],\n",
        "       ['don', 'many'],\n",
        "       ['well', 'make'],\n",
        "       ['doesn', 'great'],\n",
        "       ['scene', 'man'],\n",
        "       ['people', 'being'],\n",
        "       ['here', 'new'],\n",
        "       ['know', 'scene'],\n",
        "       ['over', 'over'],\n",
        "       ['being', '!'],\n",
        "       ['action', 'such'],\n",
        "       ['man', 'love'],\n",
        "       ['director', 'world'],\n",
        "       ['re', 'movies'],\n",
        "       ['such', 'through'],\n",
        "       ['new', 'doesn'],\n",
        "       ['movies', 'still'],\n",
        "       ['another', 'plot'],\n",
        "       ['through', 'don'],\n",
        "       ['big', 'know'],\n",
        "       ['made', 'both'],\n",
        "       ['go', 'another'],\n",
        "       ['better', 'makes'],\n",
        "       ['end', 'back'],\n",
        "       ['something', 'between'],\n",
        "       ['seems', 'performanc'],\n",
        "       ['work', 'go'],\n",
        "       ['nothing', 'those'],\n",
        "       ['best', 'seen'],\n",
        "       ['life', 'here'],\n",
        "       ['isn', 'seems'],\n",
        "       ['many', 'something'],\n",
        "       ['before', 'end'],\n",
        "       ['enough', 'director'],\n",
        "       ['now', 'work'],\n",
        "       ['script', 'though'],\n",
        "       ['back', 'before'],\n",
        "       ['those', 'now'],\n",
        "       ['few', 'few'],\n",
        "       ['audience', 'although'],\n",
        "       ['around', 'made'],\n",
        "       ['going', 'role'],\n",
        "       ['think', 'years'],\n",
        "       ['still', 'take'],\n",
        "       ['love', 'same'],\n",
        "       ['thing', 'action'],\n",
        "       ['funny', 'things'],\n",
        "       ['gets', 'real'],\n",
        "       ['actually', 'right'],\n",
        "       ['look', 'john'],\n",
        "       ['makes', 'audience'],\n",
        "       ['down', 'down'],\n",
        "       ['though', 'young'],\n",
        "       ['take', 'big'],\n",
        "       ['comedy', 'around'],\n",
        "       ['last', 've'],\n",
        "       ['ve', 'family'],\n",
        "       ['real', 're'],\n",
        "       ['things', 'enough'],\n",
        "       ['between', 'gets'],\n",
        "       ['same', 'last'],\n",
        "       ['great', 'find'],\n",
        "       ['fact', 'quite'],\n",
        "       ['m', 'going'],\n",
        "       ['played', 'each'],\n",
        "       ['minutes', 'come'],\n",
        "       ['role', 'fact'],\n",
        "       ['long', 'cast'],\n",
        "       ['plays', 'played'],\n",
        "       ['point', 'actually'],\n",
        "       ['acting', 'year'],\n",
        "       ['actors', 'takes'],\n",
        "       ['seen', 'star'],\n",
        "       ['guy', 'look'],\n",
        "       ['world', 'without'],\n",
        "       ['find', 'comedy'],\n",
        "       ['come', 'think'],\n",
        "       ['cast', 'funny'],\n",
        "       ['years', 'better'],\n",
        "       ['d', 'comes'],\n",
        "       ['comes', 'plays'],\n",
        "       ['john', 'long'],\n",
        "       ['old', 'old'],\n",
        "       ['original', 'isn'],\n",
        "       ['show', 'show'],\n",
        "       ['right', 'during'],\n",
        "       ['anything', 'part'],\n",
        "       ['goes', 'himself'],\n",
        "       ['performanc', 'original'],\n",
        "       ['course', 'again'],\n",
        "       ['didn', 'always'],\n",
        "       ['interestin', 'thing']], \n",
        "      dtype='|S10')"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}