{
 "metadata": {
  "name": "",
  "signature": "sha256:4c2bca53c2d8dd4df8e451c9704164961e693e517fbdfd34823a549d32572581"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Loss:\n",
      "    \n",
      "    #Calcule la valeur du loss \u00e9tant donn\u00e9es les valeurs pr\u00e9dites et d\u00e9sir\u00e9es\n",
      "    def getLossValue(self,predicted_output,desired_output):\n",
      "        pass\n",
      "    \n",
      "    #Calcule le gradient (pour chaque celllule d'entr\u00e9e) du co\u00fbt\n",
      "    def backward(self, predicted_output,desired_output):\n",
      "        pass "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SquareLoss(Loss):\n",
      "    \n",
      "    def getLossValue(self,predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        \n",
      "        return sum( np.square(y_pred-y) )\n",
      "          \n",
      "    def backward(self, predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        delta_out = 2*(y_pred-y)/y.shape[0]\n",
      "        return delta_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class HingeLoss(Loss): #L = max(0,-y_pred*y)\n",
      "\n",
      "    def getLossValue(self,predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        loss = sum(np.where(y_pred*y >= 0,0,-y_pred*y))\n",
      "        return loss\n",
      "          \n",
      "    def backward(self, predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        delta_out = np.where(y_pred*y > 0,0,-y)/y.shape[0]\n",
      "        return delta_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Module:\n",
      "    \n",
      "    #Permet le calcul de la sortie du module\n",
      "    def forward(self,input):\n",
      "        pass\n",
      "    \n",
      "    #Permet le calcul du gradient des cellules d'entr\u00e9e\n",
      "    def backward_delta(self,input,delta_module_suivant):\n",
      "        pass\n",
      "    \n",
      "    #Permet d'initialiser le gradient du module\n",
      "    def init_gradient(self):\n",
      "        pass\n",
      "    \n",
      "    #Permet la mise \u00e0 jour des parma\u00e8tres du module avcec la valeur courante di gradient\n",
      "    def update_parameters(self,gradient_step):\n",
      "        pass\n",
      "    \n",
      "    #Permet de mettre \u00e0 jour la valeur courante du gradient par addition\n",
      "    def backward_update_gradient(self,input,delta_module_suivant):\n",
      "        pass\n",
      "    \n",
      "    #Permet de faire les deux backwar simultan\u00e9ment\n",
      "    def backward(self,input,delta_module_suivant):\n",
      "        self.backward_update_gradient(input,delta_module_suivant)\n",
      "        return self.backward_delta(input,delta_module_suivant)\n",
      "\n",
      "    #Retourne les param\u00e8tres du module\n",
      "    def get_parameters(self):\n",
      "        pass\n",
      "    \n",
      "    #Initialize al\u00e9atoirement les param\u00e8tres du module\n",
      "    def randomize_parameters(self, variance):\n",
      "        pass\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LinearModule(Module):\n",
      "    \n",
      "    def __init__(self,input_dimension,output_dimension):\n",
      "        self.input_dimension = input_dimension\n",
      "        self.output_dimension = output_dimension \n",
      "        self.theta=np.zeros((self.input_dimension,self.output_dimension))\n",
      "        self.gradient = np.ones((self.input_dimension,self.output_dimension))\n",
      "    \n",
      "    #Permet le calcul de la sortie du module\n",
      "    def forward(self,input):\n",
      "        out = np.dot(input,self.theta)\n",
      "        return out\n",
      "    \n",
      "    #Permet le calcul du gradient des cellules d'entr\u00e9e\n",
      "    def backward_delta(self,input,delta_module_suivant):\n",
      "        \n",
      "        delta_in = np.dot(input,delta_module_suivant)\n",
      "        return delta_in\n",
      "    \n",
      "    #Permet d'initialiser le gradient du module\n",
      "    def init_gradient(self):\n",
      "        self.gradient = np.zeros((self.input_dimension,self.output_dimension))\n",
      "    \n",
      "    #Permet la mise \u00e0 jour des parma\u00e8tres du module avcec la valeur courante di gradient\n",
      "    def update_parameters(self,gradient_step):\n",
      "        self.theta += -gradient_step*self.gradient\n",
      "    \n",
      "    #Permet de mettre \u00e0 jour la valeur courante du gradient par addition\n",
      "    def backward_update_gradient(self,input,delta_module_suivant):\n",
      "        \n",
      "        input.shape = (input.shape[0],1)\n",
      "        delta_module_suivant.shape = (1,delta_module_suivant.shape[0])\n",
      "        self.gradient += np.dot(input,delta_module_suivant)\n",
      "        \n",
      "    #Retourne les param\u00e8tres du module\n",
      "    def get_parameters(self):\n",
      "        return self.theta\n",
      "    \n",
      "    #Initialize al\u00e9atoirement les p$aram\u00e8tres du module\n",
      "    def randomize_parameters(self, variance):\n",
      "        #self.theta=np.random.randint(0,1,(self.input_dimension,self.output_dimension))\n",
      "        #self.theta=np.random.randint(-variance,variance,(self.input_dimension,self.output_dimension))\n",
      "        self.theta=np.zeros((self.input_dimension,self.output_dimension))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TanHModule( Module ) :\n",
      "    def __init_(self,dimension) :\n",
      "        self.X = dimension\n",
      "    def forward(self,x):\n",
      "        return np.tanh(x) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kernel_bias(x):\n",
      "    n = x.shape[0]\n",
      "    return np.hstack((x ,np.ones((n, 1))  ))\n",
      "\n",
      "def kernel_poly(x):\n",
      "    output = np.zeros((x.shape[0],6))\n",
      "    \n",
      "    output[:,0]=x[:,0]\n",
      "    output[:,1]=x[:,1]\n",
      "    output[:,2]=np.ones((x.shape[0]))\n",
      "    output[:,3]=x[:,0]*x[:,0]\n",
      "    output[:,4]=x[:,1]*x[:,1]\n",
      "    output[:,5]=x[:,0]*x[:,1]\n",
      "\n",
      "    \n",
      "    return output "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Fonction pour plotter les classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_frontiere(x,f,step=20):\n",
      "    mmax=x.max(0)\n",
      "    mmin=x.min(0)\n",
      "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
      "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
      "    \n",
      "    # calcul de la prediction pour chaque point de la grille\n",
      "    res=np.array([f(grid[i,:])[0] for i in range(len(grid)) ])\n",
      "    res=res.reshape(x1grid.shape)\n",
      "    # tracer des frontieres\n",
      "    plt.contourf(x1grid,x2grid,res,colors=[\"orange\",\"gray\"],levels=[-1000,0,1000],linewidth=2)\n",
      "\n",
      "\n",
      "def f(x):\n",
      "    score=[x[0]+x[1]]\n",
      "    return(score)\n",
      "\n",
      "def plot2DSet(set):\n",
      "    plt.scatter(set.x[:,0],set.x[:,1], c=set.y)\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Use this function if using kernel trick"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_frontiere2(x, f, kernel, step=20):\n",
      "    mmax = x.max(0)\n",
      "    mmin = x.min(0)\n",
      "    x1grid , x2grid = np.meshgrid(np.linspace(mmin[0], mmax[0], step),\n",
      "                                  np.linspace(mmin[1], mmax[1], step))\n",
      "    grid = np.hstack((x1grid.reshape(x1grid.size, 1),\n",
      "                      x2grid.reshape(x2grid.size, 1)))\n",
      "    # calcul de la prediction pour chaque point de la grille\n",
      "    res = np.array([f(kernel(np.array([grid[i,:]]))[0])[0] for i in range(len(grid))])\n",
      "    res = res.reshape(x1grid.shape)\n",
      "    # tracer des frontieres\n",
      "    plt.contourf(x1grid, x2grid, res,\n",
      "                 colors=[\"orange\",\"gray\"], levels=[-1000, 0, 1000], linewidth=2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CREATE RANDOM DATASET"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LabeledSet:\n",
      "    \n",
      "    def __init__(self,x,y,input_dim,output_dim):\n",
      "        self.x = x\n",
      "        self.y = y \n",
      "        self.input_dim = x.shape\n",
      "        self.output_dim = y.shape\n",
      "        \n",
      "    #Renvoie la dimension de l'espace d'entr\u00e9e\n",
      "    def getInputDimension(self):\n",
      "        return self.input_dim\n",
      "        \n",
      "    #Renvoie la dimension de l'espace de sortie\n",
      "    def getOutputDimension(self):\n",
      "        return self.output_dim\n",
      "        \n",
      "    #Renvoie le nombre d'exemple dans le set\n",
      "    def size(self):\n",
      "        return self.x.size\n",
      "    #Renvoie la valeur de x_i\n",
      "    def getX(self,i):\n",
      "        return self.x[i]\n",
      "    \n",
      "    #Renvouie la valeur de y_i\n",
      "    def getY(self,i):\n",
      "       return self.y[i]\n",
      "\n",
      "        \n",
      "\n",
      "def createGaussianDataset(positive_center_1,positive_center_2,positive_sigma,negative_center_1,negative_center_2,negative_sigma,nb_points):\n",
      "    #Center of the two gaussian distribution\n",
      "    mean1 = np.array([positive_center_1,positive_center_2])\n",
      "    mean2 = np.array([negative_center_1,negative_center_2])\n",
      "     \n",
      "    #Covariance matrix of the two gaussian distribution\n",
      "    cov1 = positive_sigma*np.eye(mean1.shape[0])\n",
      "    cov2 = negative_sigma*np.eye(mean2.shape[0])\n",
      "           \n",
      "    #Generating gaussian data1 with corresponding label1 \n",
      "    data1 = np.random.multivariate_normal(mean1,cov1,nb_points)\n",
      "    label1 = np.ones((data1.shape[0],1))\n",
      "        \n",
      "    #Generating gaussian data2 with corresponding label2\n",
      "    data2 = np.random.multivariate_normal(mean2,cov2,nb_points)\n",
      "    label2 = -np.ones((data2.shape[0],1))\n",
      "        \n",
      "    x=np.vstack((data1,data2))\n",
      "    y=np.vstack((label1,label2))\n",
      "    \n",
      "    set=LabeledSet(x,y,2,1)\n",
      "    return set\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# coding: utf-8\n",
      "\n",
      "# In[1]:\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "class Loss:\n",
      "    \n",
      "    #Calcule la valeur du loss \u00e9tant donn\u00e9es les valeurs pr\u00e9dites et d\u00e9sir\u00e9es\n",
      "    def getLossValue(self,predicted_output,desired_output):\n",
      "        pass\n",
      "    \n",
      "    #Calcule le gradient (pour chaque celllule d'entr\u00e9e) du co\u00fbt\n",
      "    def backward(self, predicted_output,desired_output):\n",
      "        pass \n",
      "\n",
      "\n",
      "# In[3]:\n",
      "\n",
      "class SquareLoss(Loss):\n",
      "    \n",
      "    def getLossValue(self,predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        \n",
      "        return sum( np.square(y_pred-y) )\n",
      "          \n",
      "    def backward(self, predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        delta_out = 2*(y_pred-y)/y.shape[0]\n",
      "        return delta_out\n",
      "\n",
      "\n",
      "# In[4]:\n",
      "\n",
      "class HingeLoss(Loss): #L = max(0,-y_pred*y)\n",
      "\n",
      "    def getLossValue(self,predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        loss = sum(np.where(y_pred*y >= 0,0,-y_pred*y))\n",
      "        return loss\n",
      "          \n",
      "    def backward(self, predicted_output,desired_output):\n",
      "        y_pred = predicted_output\n",
      "        y = desired_output\n",
      "        delta_out = np.where(y_pred*y > 0,0,-y)/y.shape[0]\n",
      "        return delta_out\n",
      "\n",
      "\n",
      "# In[5]:\n",
      "\n",
      "class Module:\n",
      "    \n",
      "    #Permet le calcul de la sortie du module\n",
      "    def forward(self,input):\n",
      "        pass\n",
      "    \n",
      "    #Permet le calcul du gradient des cellules d'entr\u00e9e\n",
      "    def backward_delta(self,input,delta_module_suivant):\n",
      "        pass\n",
      "    \n",
      "    #Permet d'initialiser le gradient du module\n",
      "    def init_gradient(self):\n",
      "        pass\n",
      "    \n",
      "    #Permet la mise \u00e0 jour des parma\u00e8tres du module avcec la valeur courante di gradient\n",
      "    def update_parameters(self,gradient_step):\n",
      "        pass\n",
      "    \n",
      "    #Permet de mettre \u00e0 jour la valeur courante du gradient par addition\n",
      "    def backward_update_gradient(self,input,delta_module_suivant):\n",
      "        pass\n",
      "    \n",
      "    #Permet de faire les deux backwar simultan\u00e9ment\n",
      "    def backward(self,input,delta_module_suivant):\n",
      "        self.backward_update_gradient(input,delta_module_suivant)\n",
      "        return self.backward_delta(input,delta_module_suivant)\n",
      "\n",
      "    #Retourne les param\u00e8tres du module\n",
      "    def get_parameters(self):\n",
      "        pass\n",
      "    \n",
      "    #Initialize al\u00e9atoirement les param\u00e8tres du module\n",
      "    def randomize_parameters(self, variance):\n",
      "        pass\n",
      "    \n",
      "\n",
      "\n",
      "# In[6]:\n",
      "\n",
      "class LinearModule(Module):\n",
      "    \n",
      "    def __init__(self,input_dimension,output_dimension):\n",
      "        self.input_dimension = input_dimension\n",
      "        self.output_dimension = output_dimension \n",
      "        self.theta=np.zeros((self.input_dimension,self.output_dimension))\n",
      "        self.gradient = np.ones((self.input_dimension,self.output_dimension))\n",
      "    \n",
      "    #Permet le calcul de la sortie du module\n",
      "    def forward(self,input):\n",
      "        out = np.dot(input,self.theta)\n",
      "        return out\n",
      "    \n",
      "    #Permet le calcul du gradient des cellules d'entr\u00e9e\n",
      "    def backward_delta(self,input,delta_module_suivant):\n",
      "        \n",
      "        delta_in = np.dot(input,delta_module_suivant)\n",
      "        return delta_in\n",
      "    \n",
      "    #Permet d'initialiser le gradient du module\n",
      "    def init_gradient(self):\n",
      "        self.gradient = np.zeros((self.input_dimension,self.output_dimension))\n",
      "    \n",
      "    #Permet la mise \u00e0 jour des parma\u00e8tres du module avcec la valeur courante di gradient\n",
      "    def update_parameters(self,gradient_step):\n",
      "        self.theta += -gradient_step*self.gradient\n",
      "    \n",
      "    #Permet de mettre \u00e0 jour la valeur courante du gradient par addition\n",
      "    def backward_update_gradient(self,input,delta_module_suivant):\n",
      "        \n",
      "        input.shape = (input.shape[0],1)\n",
      "        delta_module_suivant.shape = (1,delta_module_suivant.shape[0])\n",
      "        self.gradient += np.dot(input,delta_module_suivant)\n",
      "        \n",
      "    #Retourne les param\u00e8tres du module\n",
      "    def get_parameters(self):\n",
      "        return self.theta\n",
      "    \n",
      "    #Initialize al\u00e9atoirement les p$aram\u00e8tres du module\n",
      "    def randomize_parameters(self, variance):\n",
      "        #self.theta=np.random.randint(0,1,(self.input_dimension,self.output_dimension))\n",
      "        #self.theta=np.random.randint(-variance,variance,(self.input_dimension,self.output_dimension))\n",
      "        self.theta=np.zeros((self.input_dimension,self.output_dimension))\n",
      "\n",
      "\n",
      "# In[8]:\n",
      "\n",
      "def kernel_bias(x):\n",
      "    n = x.shape[0]\n",
      "    return np.hstack((x ,np.ones((n, 1))  ))\n",
      "\n",
      "def kernel_poly(x):\n",
      "    output = np.zeros((x.shape[0],6))\n",
      "    \n",
      "    output[:,0]=x[:,0]\n",
      "    output[:,1]=x[:,1]\n",
      "    output[:,2]=np.ones((x.shape[0]))\n",
      "    output[:,3]=x[:,0]*x[:,0]\n",
      "    output[:,4]=x[:,1]*x[:,1]\n",
      "    output[:,5]=x[:,0]*x[:,1]\n",
      "\n",
      "    \n",
      "    return output \n",
      "\n",
      "\n",
      "## Fonction pour plotter les classifier\n",
      "\n",
      "# In[9]:\n",
      "\n",
      "def plot_frontiere(x,f,step=20):\n",
      "    mmax=x.max(0)\n",
      "    mmin=x.min(0)\n",
      "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
      "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
      "    \n",
      "    # calcul de la prediction pour chaque point de la grille\n",
      "    res=np.array([f(grid[i,:])[0] for i in range(len(grid)) ])\n",
      "    res=res.reshape(x1grid.shape)\n",
      "    # tracer des frontieres\n",
      "    plt.contourf(x1grid,x2grid,res,colors=[\"orange\",\"gray\"],levels=[-1000,0,1000],linewidth=2)\n",
      "\n",
      "\n",
      "def f(x):\n",
      "    score=[x[0]+x[1]]\n",
      "    return(score)\n",
      "\n",
      "def plot2DSet(set):\n",
      "    plt.scatter(set.x[:,0],set.x[:,1], c=set.y)\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    return\n",
      "\n",
      "\n",
      "## Use this function if using kernel trick\n",
      "\n",
      "# In[10]:\n",
      "\n",
      "def plot_frontiere2(x, f, kernel, step=20):\n",
      "    mmax = x.max(0)\n",
      "    mmin = x.min(0)\n",
      "    x1grid , x2grid = np.meshgrid(np.linspace(mmin[0], mmax[0], step),\n",
      "                                  np.linspace(mmin[1], mmax[1], step))\n",
      "    grid = np.hstack((x1grid.reshape(x1grid.size, 1),\n",
      "                      x2grid.reshape(x2grid.size, 1)))\n",
      "    # calcul de la prediction pour chaque point de la grille\n",
      "    res = np.array([f(kernel(np.array([grid[i,:]]))[0])[0] for i in range(len(grid))])\n",
      "    res = res.reshape(x1grid.shape)\n",
      "    # tracer des frontieres\n",
      "    plt.contourf(x1grid, x2grid, res,\n",
      "                 colors=[\"orange\",\"gray\"], levels=[-1000, 0, 1000], linewidth=2)\n",
      "\n",
      "\n",
      "## CREATE RANDOM DATASET\n",
      "\n",
      "# In[11]:\n",
      "\n",
      "class LabeledSet:\n",
      "    \n",
      "    def __init__(self,x,y,input_dim,output_dim):\n",
      "        self.x = x\n",
      "        self.y = y \n",
      "        self.input_dim = x.shape\n",
      "        self.output_dim = y.shape\n",
      "        \n",
      "    #Renvoie la dimension de l'espace d'entr\u00e9e\n",
      "    def getInputDimension(self):\n",
      "        return self.input_dim\n",
      "        \n",
      "    #Renvoie la dimension de l'espace de sortie\n",
      "    def getOutputDimension(self):\n",
      "        return self.output_dim\n",
      "        \n",
      "    #Renvoie le nombre d'exemple dans le set\n",
      "    def size(self):\n",
      "        return self.x.size\n",
      "    #Renvoie la valeur de x_i\n",
      "    def getX(self,i):\n",
      "        return self.x[i]\n",
      "    \n",
      "    #Renvouie la valeur de y_i\n",
      "    def getY(self,i):\n",
      "       return self.y[i]\n",
      "\n",
      "        \n",
      "\n",
      "def createGaussianDataset(positive_center_1,positive_center_2,positive_sigma,negative_center_1,negative_center_2,negative_sigma,nb_points):\n",
      "    #Center of the two gaussian distribution\n",
      "    mean1 = np.array([positive_center_1,positive_center_2])\n",
      "    mean2 = np.array([negative_center_1,negative_center_2])\n",
      "     \n",
      "    #Covariance matrix of the two gaussian distribution\n",
      "    cov1 = positive_sigma*np.eye(mean1.shape[0])\n",
      "    cov2 = negative_sigma*np.eye(mean2.shape[0])\n",
      "           \n",
      "    #Generating gaussian data1 with corresponding label1 \n",
      "    data1 = np.random.multivariate_normal(mean1,cov1,nb_points)\n",
      "    label1 = np.ones((data1.shape[0],1))\n",
      "        \n",
      "    #Generating gaussian data2 with corresponding label2\n",
      "    data2 = np.random.multivariate_normal(mean2,cov2,nb_points)\n",
      "    label2 = -np.ones((data2.shape[0],1))\n",
      "        \n",
      "    x=np.vstack((data1,data2))\n",
      "    y=np.vstack((label1,label2))\n",
      "    \n",
      "    set=LabeledSet(x,y,2,1)\n",
      "    return set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In[7]:\n",
      "\n",
      "class TanHModule( Module ) :\n",
      "    def __init_(self,dimension) :\n",
      "        self.x = dimension\n",
      "    def forward(self,x):\n",
      "        return np.tanh(x) \n",
      "    \n",
      "    def __init__(self,input_dimension,output_dimension):\n",
      "        self.input_dimension = input_dimension\n",
      "        self.output_dimension = output_dimension \n",
      "        self.theta=np.zeros((self.input_dimension,self.output_dimension))\n",
      "        self.gradient = np.ones((self.input_dimension,self.output_dimension))\n",
      "    \n",
      "    #Permet le calcul de la sortie du module\n",
      "    def forward(self,input):\n",
      "        out = np.dot(input,self.theta)\n",
      "        return out\n",
      "    \n",
      "    #Permet le calcul du gradient des cellules d'entr\u00e9e\n",
      "    def backward_delta(self,input,delta_module_suivant):\n",
      "        \n",
      "        delta_in = np.dot(input,delta_module_suivant)\n",
      "        return delta_in\n",
      "    \n",
      "    #Permet d'initialiser le gradient du module\n",
      "    def init_gradient(self):\n",
      "        self.gradient = np.zeros((self.input_dimension,self.output_dimension))\n",
      "    \n",
      "    #Permet la mise \u00e0 jour des parma\u00e8tres du module avcec la valeur courante di gradient\n",
      "    def update_parameters(self,gradient_step):\n",
      "        self.theta += -gradient_step*self.gradient\n",
      "    \n",
      "    #Permet de mettre \u00e0 jour la valeur courante du gradient par addition\n",
      "    def backward_update_gradient(self,input,delta_module_suivant):\n",
      "        \n",
      "        input.shape = (input.shape[0],1)\n",
      "        delta_module_suivant.shape = (1,delta_module_suivant.shape[0])\n",
      "        self.gradient += np.dot(input,delta_module_suivant)\n",
      "        \n",
      "    #Retourne les param\u00e8tres du module\n",
      "    def get_parameters(self):\n",
      "        return self.theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}