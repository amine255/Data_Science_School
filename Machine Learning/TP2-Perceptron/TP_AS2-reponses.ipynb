{
 "metadata": {
  "name": "",
  "signature": "sha256:a2d4226d6f428411bee7a5cbf66ba342770d73367e4cb15733bc44fe96fd3992"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TP2 : Programmation du Perceptron\n",
      "=======\n",
      "\n",
      "Dans ce TP, nous allons principalement programmer un perceptron, et mettre en place une \"architecture\" de code nous permettant petit \u00e0 petit d'impl\u00e9menter des Deep Neural Networks. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 1: Dataset\n",
      "------\n",
      "\n",
      "La premi\u00e8re \u00e9tape consiste \u00e0 d\u00e9finir une classe permettant de stocker les donn\u00e9es d'apprentissage, de validation et de test. Nous consid\u00e9rerons que les donn\u00e9es tiennent en m\u00e9moire. Nous allons d\u00e9finir une classe permettant de stocker des couples $\\{(x_1,y_1),...,(x_n,y_n)\\}$. Les $x_i$ et $y_i$ seront des tableaux numpy "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class LabeledSet:\n",
      "    \n",
      "    def __init__(self,x,y,input_dim,output_dim):\n",
      "        self.x = x\n",
      "        self.y = y \n",
      "        self.input_dim = x.shape\n",
      "        self.output_dim = y.shape\n",
      "        \n",
      "    #Renvoie la dimension de l'espace d'entr\u00e9e\n",
      "    def getInputDimension(self):\n",
      "        return self.input_dim\n",
      "        \n",
      "    #Renvoie la dimension de l'espace de sortie\n",
      "    def getOutputDimension(self):\n",
      "        return self.output_dim\n",
      "        \n",
      "    #Renvoie le nombre d'exemple dans le set\n",
      "    def size(self):\n",
      "        return self.x.size\n",
      "    #Renvoie la valeur de x_i\n",
      "    def getX(self,i):\n",
      "        return self.x[i]\n",
      "    \n",
      "    #Renvouie la valeur de y_i\n",
      "    def getY(self,i):\n",
      "       return self.y[i]\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous allons pour l'instant nous int\u00e9resser \u00e0 des datasets \"jouet\" g\u00e9n\u00e9res selon des distributions choisies \u00e0 la main. Commen\u00e7ons par un dataset en 2 dimensions (entr\u00e9e) et 1 dimension (sortie): $x_i \\in \\mathbb{R}^2$, $y_i \\in [-1;+1]$ telle que les donn\u00e9es sont g\u00e9n\u00e9res selon deux Gaussiennes. Pour cela, nous utiliserons la fonction numpy.random.multivariate_normal  - http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.multivariate_normal.html -  ainsi que la m\u00e9thode numpy.vstack  - http://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html - pour concaterner des vecteurs "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class createGaussianDataset:\n",
      "    \n",
      "    \n",
      "    def __init__(self,positive_center_1,positive_center_2,positive_sigma,negative_center_1,negative_center_2,negative_sigma,nb_points):\n",
      "      \n",
      "        #Center of the two gaussian distribution\n",
      "        mean1 = np.array([positive_center_1,positive_center_2])\n",
      "        mean2 = np.array([negative_center_1,negative_center_2])\n",
      "     \n",
      "        #Covariance matrix of the two gaussian distribution\n",
      "        cov1 = positive_sigma*np.eye(mean1.shape[0])\n",
      "        cov2 = negative_sigma*np.eye(mean2.shape[0])\n",
      "           \n",
      "        #Generating gaussian data1 with corresponding label1 \n",
      "        self.data1 = np.random.multivariate_normal(mean1,cov1,nb_points)\n",
      "        self.label1 = np.ones((self.data1.shape[0],1))\n",
      "        \n",
      "        #Generating gaussian data2 with corresponding label2\n",
      "        self.data2 = np.random.multivariate_normal(mean2,cov2,nb_points)\n",
      "        self.label2 = -np.ones((self.data2.shape[0],1))\n",
      "        \n",
      "    def getXs(self):\n",
      "        #Concatenate data1 and data1 to forme the dataset\n",
      "        data = np.vstack((self.data1,self.data2))\n",
      "        return data\n",
      "        \n",
      "    \n",
      "    def getYs(self):\n",
      "        #Concatenate label1 and label2 to form label\n",
      "        label = np.vstack((self.label1,self.label2))\n",
      "        return label\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set=createGaussianDataset(1,1,1,-1,-1,1,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Le data set peut \u00eatre affich\u00e9 en utilisatn matplotlib (pour v\u00e9rifier). Nous utiliserons la commande matplotlib.pyplot.scatter permettant de dessiner un nuage de points - http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter -"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def plot2DSet(set):\n",
      "    plt.scatter(set.data1[:,0],set.data1[:,1], marker='o', label = 'class1')\n",
      "    plt.scatter(set.data2[:,0],set.data2[:,1], marker='x', label = 'class2')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maintenant, nous allons faire la m\u00eame chose, mais en dessinant une fronti\u00e8re de d\u00e9cision donn\u00e9e par une fonction $f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^1$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_frontiere(x,f,step=20):\n",
      "    mmax=x.max(0)\n",
      "    mmin=x.min(0)\n",
      "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
      "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
      "    \n",
      "    # calcul de la prediction pour chaque point de la grille\n",
      "    res=np.array([f(grid[i,:])[0] for i in range(len(grid)) ])\n",
      "    res=res.reshape(x1grid.shape)\n",
      "    # tracer des frontieres\n",
      "    plt.contourf(x1grid,x2grid,res,colors=[\"orange\",\"gray\"],levels=[-1000,0,1000],linewidth=2)\n",
      "\n",
      "\n",
      "def f(x):\n",
      "    score=[x[0]+x[1]]\n",
      "    return(score)\n",
      "\n",
      "set=createGaussianDataset(1,1,1,-15,-15,1,200)\n",
      "\n",
      "x=set.getXs()\n",
      "y=set.getYs()\n",
      "plot_frontiere(x,f)\n",
      "plot2DSet(set)\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 2 : Le Perceptron\n",
      "--------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous allons commencer par cr\u00e9er une classe permettant de d\u00e9finir un pr\u00e9dicteur. Basiquement, un pr\u00e9dicteur est une fonction qui prend un vecteur et produit un vecteur, et que l'on peut entrainer sur un \"dataset\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class Predictor:\n",
      "    def __init__(self):\n",
      "\n",
      "    \n",
      "    \n",
      "    #Permet de calculer la prediction sur x\n",
      "    def predict(self,x):\n",
      "        raise NotImplementedError(\"Please Implement this method\")\n",
      "\n",
      "    \n",
      "    #Permet d'entrainer le modele\n",
      "    def train(self,labeledSet):\n",
      "        raise NotImplementedError(\"Please Implement this method\")\n",
      "    \n",
      "    #Permet de calculer la qualit\u00e9 du syst\u00e8me (en classification monolabel). ATTENTION, deux cas: outputDimension==1 et outputDimension>1\n",
      "    def computeMonolabelAccuracy(self,labeledset):\n",
      "        raise NotImplementedError(\"Please Implement this method\")\n",
      "    \n",
      "       \n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Le premier classifieur \u00e0 impl\u00e9menter sera le classifieur perceptron vu en cours"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class Perceptron():\n",
      "    \n",
      "    def __init__(self,gradient_step,nb_iterations):\n",
      "        self.learning_rate = gradient_step\n",
      "        self.nb_iterations = nb_iterations\n",
      "        \n",
      "        \n",
      "        self.theta = 0\n",
      "        \n",
      "        unit_step = lambda x: -1 if x < 0 else 1\n",
      "        self.unit_step = unit_step\n",
      "        \n",
      "            \n",
      "    def predict(self,data):\n",
      "        \n",
      "        data = np.hstack((np.ones((data.shape[0],1)),data))\n",
      "            \n",
      "        predict_stack = np.zeros((data.shape[0],1))\n",
      "        B = data\n",
      "        \n",
      "        \n",
      "        for i in range(len(B)):\n",
      "            predict_stack[i,0] = self.unit_step(np.dot(B[i,:],self.theta))\n",
      "        return predict_stack\n",
      "         \n",
      "           \n",
      "            \n",
      "    def train(self,labeledSet):\n",
      "            \n",
      "        data = np.hstack((np.ones((labeledSet.x.shape[0],1)),labeledSet.x))\n",
      "        label = labeledSet.y\n",
      "        \n",
      "        self.theta = np.zeros((data.shape[1],1))\n",
      "        \n",
      "        eta = self.learning_rate\n",
      "        n = self.nb_iterations\n",
      "        \n",
      "        \n",
      "\n",
      "        for i in range(n):\n",
      "\n",
      "            t =np.random.choice(data.shape[0])\n",
      "            x = data[t,:]\n",
      "\n",
      "            prediction = self.unit_step(np.dot(x,self.theta))\n",
      "   \n",
      "            expected = label[t]\n",
      "                #print expected\n",
      "\n",
      "            error = label[t] - prediction\n",
      "               \n",
      "            learning = eta*(  error   )*x\n",
      "            learning.shape = ((self.theta.shape[0],1))\n",
      "            #print learning\n",
      "            \n",
      "            self.theta += learning\n",
      "        return self.theta\n",
      "    \n",
      "      \n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 244
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va maintenant tester notre perceptron sur l'ensemble pr\u00e9c\u00e9dent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainset=createGaussianDataset(1,1,1,-1,-1,1,200)\n",
      "set = LabeledSet(trainset.getXs(),trainset.getYs(),trainset.getXs().shape,trainset.getYs().shape)\n",
      "\n",
      "perceptron=Perceptron(0.001,10)\n",
      "\n",
      "theta = perceptron.train(set)\n",
      "print theta\n",
      "\n",
      "prediction = perceptron.predict(set.x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.        ]\n",
        " [ 0.00433282]\n",
        " [ 0.00262684]]\n"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualiser la frontiere de d\u00e9cision obtenus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "x=trainset.getXs()\n",
      "y=trainset.getYs()\n",
      "plot_frontiere(x,f)\n",
      "plot2DSet(trainset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 3 : Tester le Perceptron\n",
      "------\n",
      "On va maintenant cr\u00e9er des ensembles de test et de train selon plusieurs distribution et tracer les courbes d'apprentissage (accuraacy) sur train et test dans le temps. Pouvez vous faire apparaitre un effet de sur-apprentissage? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pouvez vous faire apparaitre un cas ou le perceptron ne peut pas apprendre"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 4 : Kernel Trick\n",
      "-----\n",
      "On va transformer nos vecteurs d'entr\u00e9e de la mani\u00e8re suivante: $(x_1,x_2) \\rightarrow $(x_1,x_2,1)$. Apprenez le perceptron sur le nouvel ensemble et visualisez sa frontiere de d\u00e9cision. Que pouvez vous dire ? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va transformer nos vecteurs d'entr\u00e9e de la mani\u00e8re suivante: $(x_1,x_2) \\rightarrow $(x_1,x_2,1,x_1*x_1,x_2*x_2,x_1*x_2)$. Apprenez le perceptron sur le nouvel ensemble et visualisez sa frontiere de d\u00e9cision. Que pouvez vous dire ? Pourquoi observe-t-on cette fronti\u00e8re de d\u00e9cision ? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 5 : UCI\n",
      "-----\n",
      "\n",
      "Plusieurs datasets sont t\u00e9l\u00e9chargeables ici:  http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/\n",
      "\n",
      "* Impl\u00e9mentez une fonction permettant de les charger\n",
      "* Impl\u00e9mnetez une fonction permettant de les \"splitter\" en train et test\n",
      "* Lancer les diff\u00e9rentes perceptrons la dessus et tracer les courbes de performance\n",
      "\n",
      "(Datasets conseill\u00e9s: sonar, jeart, breast-cancer et ionosphere)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}