{
 "metadata": {
  "name": "",
  "signature": "sha256:319817c00585facb4c365246dcaac35709229a72668bcfc65396d9714f99ecd7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TP2 : Programmation du Perceptron\n",
      "=======\n",
      "\n",
      "Dans ce TP, nous allons principalement programmer un perceptron, et mettre en place une \"architecture\" de code nous permettant petit \u00e0 petit d'impl\u00e9menter des Deep Neural Networks. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 1: Dataset\n",
      "------\n",
      "\n",
      "La premi\u00e8re \u00e9tape consiste \u00e0 d\u00e9finir une classe permettant de stocker les donn\u00e9es d'apprentissage, de validation et de test. Nous consid\u00e9rerons que les donn\u00e9es tiennent en m\u00e9moire. Nous allons d\u00e9finir une classe permettant de stocker des couples $\\{(x_1,y_1),...,(x_n,y_n)\\}$. Les $x_i$ et $y_i$ seront des tableaux numpy "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class LabeledSet:\n",
      "    \n",
      "    def __init__(self,x,y,input_dim,output_dim):\n",
      "        self.x = x\n",
      "        self.y = y \n",
      "        self.input_dim = x.shape\n",
      "        self.output_dim = y.shape\n",
      "        \n",
      "    #Renvoie la dimension de l'espace d'entr\u00e9e\n",
      "    def getInputDimension(self):\n",
      "        return self.input_dim\n",
      "        \n",
      "    #Renvoie la dimension de l'espace de sortie\n",
      "    def getOutputDimension(self):\n",
      "        return self.output_dim\n",
      "        \n",
      "    #Renvoie le nombre d'exemple dans le set\n",
      "    def size(self):\n",
      "        return self.x.size\n",
      "    #Renvoie la valeur de x_i\n",
      "    def getX(self,i):\n",
      "        return self.x[i]\n",
      "    \n",
      "    #Renvouie la valeur de y_i\n",
      "    def getY(self,i):\n",
      "       return self.y[i]\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous allons pour l'instant nous int\u00e9resser \u00e0 des datasets \"jouet\" g\u00e9n\u00e9res selon des distributions choisies \u00e0 la main. Commen\u00e7ons par un dataset en 2 dimensions (entr\u00e9e) et 1 dimension (sortie): $x_i \\in \\mathbb{R}^2$, $y_i \\in [-1;+1]$ telle que les donn\u00e9es sont g\u00e9n\u00e9res selon deux Gaussiennes. Pour cela, nous utiliserons la fonction numpy.random.multivariate_normal  - http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.multivariate_normal.html -  ainsi que la m\u00e9thode numpy.vstack  - http://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html - pour concaterner des vecteurs "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class createGaussianDataset:\n",
      "    \n",
      "    \n",
      "    def __init__(self,positive_center_1,positive_center_2,positive_sigma,negative_center_1,negative_center_2,negative_sigma,nb_points):\n",
      "      \n",
      "        #Center of the two gaussian distribution\n",
      "        mean1 = np.array([positive_center_1,positive_center_2])\n",
      "        mean2 = np.array([negative_center_1,negative_center_2])\n",
      "     \n",
      "        #Covariance matrix of the two gaussian distribution\n",
      "        cov1 = positive_sigma*np.eye(mean1.shape[0])\n",
      "        cov2 = negative_sigma*np.eye(mean2.shape[0])\n",
      "           \n",
      "        #Generating gaussian data1 with corresponding label1 \n",
      "        self.data1 = np.random.multivariate_normal(mean1,cov1,nb_points)\n",
      "        self.label1 = np.ones((self.data1.shape[0],1))\n",
      "        \n",
      "        #Generating gaussian data2 with corresponding label2\n",
      "        self.data2 = np.random.multivariate_normal(mean2,cov2,nb_points)\n",
      "        self.label2 = -np.ones((self.data2.shape[0],1))\n",
      "        \n",
      "    def getXs(self):\n",
      "        #Concatenate data1 and data1 to forme the dataset\n",
      "        data = np.vstack((self.data1,self.data2))\n",
      "        return data\n",
      "        \n",
      "    \n",
      "    def getYs(self):\n",
      "        #Concatenate label1 and label2 to form label\n",
      "        label = np.vstack((self.label1,self.label2))\n",
      "        return label\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set=createGaussianDataset(1,1,1,-1,-1,1,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Le data set peut \u00eatre affich\u00e9 en utilisatn matplotlib (pour v\u00e9rifier). Nous utiliserons la commande matplotlib.pyplot.scatter permettant de dessiner un nuage de points - http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter -"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def plot2DSet(set):\n",
      "    plt.scatter(set.data1[:,0],set.data1[:,1], marker='o', label = 'class1')\n",
      "    plt.scatter(set.data2[:,0],set.data2[:,1], marker='x', label = 'class2')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maintenant, nous allons faire la m\u00eame chose, mais en dessinant une fronti\u00e8re de d\u00e9cision donn\u00e9e par une fonction $f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^1$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_frontiere(x,f,step=20):\n",
      "    mmax=x.max(0)\n",
      "    mmin=x.min(0)\n",
      "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
      "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
      "    \n",
      "    # calcul de la prediction pour chaque point de la grille\n",
      "    res=np.array([f(grid[i,:])[0] for i in range(len(grid)) ])\n",
      "    res=res.reshape(x1grid.shape)\n",
      "    # tracer des frontieres\n",
      "    plt.contourf(x1grid,x2grid,res,colors=[\"orange\",\"gray\"],levels=[-1000,0,1000],linewidth=2)\n",
      "\n",
      "\n",
      "def f(x):\n",
      "    score=[x[0]+x[1]]\n",
      "    return(score)\n",
      "\n",
      "set=createGaussianDataset(1,1,1,-15,-15,1,200)\n",
      "\n",
      "x=set.getXs()\n",
      "y=set.getYs()\n",
      "plot_frontiere(x,f)\n",
      "plot2DSet(set)\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 2 : Le Perceptron\n",
      "--------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous allons commencer par cr\u00e9er une classe permettant de d\u00e9finir un pr\u00e9dicteur. Basiquement, un pr\u00e9dicteur est une fonction qui prend un vecteur et produit un vecteur, et que l'on peut entrainer sur un \"dataset\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class Predictor:\n",
      "    def __init__(self):\n",
      "\n",
      "    \n",
      "    \n",
      "    #Permet de calculer la prediction sur x\n",
      "    def predict(self,x):\n",
      "        raise NotImplementedError(\"Please Implement this method\")\n",
      "\n",
      "    \n",
      "    #Permet d'entrainer le modele\n",
      "    def train(self,labeledSet):\n",
      "        raise NotImplementedError(\"Please Implement this method\")\n",
      "    \n",
      "    #Permet de calculer la qualit\u00e9 du syst\u00e8me (en classification monolabel). ATTENTION, deux cas: outputDimension==1 et outputDimension>1\n",
      "    def computeMonolabelAccuracy(self,labeledset):\n",
      "        raise NotImplementedError(\"Please Implement this method\")\n",
      "    \n",
      "       \n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def F(data,theta):\n",
      "    return sum(np.dot(data,theta))\n",
      "\n",
      "def Unit_step(x):\n",
      "    if x > 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return -1\n",
      "    \n",
      "def Cost_fct(data,label):\n",
      "\n",
      "    A = np.zeros((data.shape[0],1))\n",
      "    for i in range(data.shape[0]):\n",
      "        A[i,:] = Unit_step(np.dot(data[i,:],theta))\n",
      "        \n",
      "    cost =  0.5*sum(np.square(A-label))\n",
      "    return cost     \n",
      "\n",
      "def Predict(data,theta):\n",
      "    A = np.zeros((data.shape[0],1))\n",
      "    B = data\n",
      "    for i in range(len(B)):\n",
      "        A[i,:] = Unit_step(np.dot(B[i,:],theta))\n",
      "    return A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import choice\n",
      "import numpy as np\n",
      "from numpy import array, dot, random\n",
      "new_data = [None]*data.shape[0]\n",
      "print len(new_data)\n",
      "\n",
      "for i in range(len(new_data)):\n",
      "    x = data[i,1]\n",
      "    y = data[i,2]\n",
      "    \n",
      "    new_data[i] =  ( array([x,y,1]), label[i,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'label' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-137-796efa8ce16a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnew_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'label' is not defined"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Le premier classifieur \u00e0 impl\u00e9menter sera le classifieur perceptron vu en cours"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "class Perceptron():\n",
      "    \n",
      "    def __init__(self,gradient_step,nb_iterations):\n",
      "        self.learning_rate = gradient_step\n",
      "        self.nb_iterations = nb_iterations\n",
      "        \n",
      "        \n",
      "        self.theta = 0\n",
      "        \n",
      "        unit_step = lambda x: -1 if x < 0 else 1\n",
      "        self.unit_step = unit_step\n",
      "        \n",
      "            \n",
      "    def predict(self,data):\n",
      "        \n",
      "        predict_stack = np.zeros((data.shape[0],1))\n",
      "        print self.theta\n",
      "        B = data\n",
      "        for i in range(len(B)):\n",
      "            predict_stack[i,:] = self.unit_step(np.dot(B[i,:],self.theta))\n",
      "            return predict_stack\n",
      "           \n",
      "            \n",
      "    def train(self,labeledSet): \n",
      "        eta = self.learning_rate\n",
      "        n = self.nb_iterations\n",
      "        \n",
      "        self.theta = np.zeros((labeledSet.x.shape[1],1))\n",
      "\n",
      "        for i in range(n):\n",
      "\n",
      "            t =np.random.choice(labeledSet.x.shape[0])\n",
      "            x = labeledSet.x[t,:]\n",
      "\n",
      "            prediction = self.unit_step(np.dot(x,self.theta))\n",
      "                #print prediction\n",
      "            expected = labeledSet.y[t]\n",
      "                #print expected\n",
      "\n",
      "            error = labeledSet.y[t] - prediction\n",
      "               # print \"learning\"\n",
      "            learning = eta*(  error   )*x\n",
      "            learning.shape = ((self.theta.shape[0],1))\n",
      "            \n",
      "            self.theta += learning\n",
      "        return self.theta\n",
      "    \n",
      "      \n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gaussian_data=createGaussianDataset(1,1,1,-3.5,-4,1,500)\n",
      "data = np.hstack(( np.ones((gaussian_data.getXs().shape[0],1)),gaussian_data.getXs() ))\n",
      "\n",
      "set = LabeledSet(data,gaussian_data.getYs(),data.shape,gaussian_data.getYs().shape)\n",
      "\n",
      "plot2DSet(gaussian_data)\n",
      "\n",
      "classifier = Perceptron(0.1,100)\n",
      "theta = classifier.train(set)\n",
      "#classifier.predict(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.4       ]\n",
        " [ 0.52059759]\n",
        " [ 0.29075009]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 145,
       "text": [
        "array([[ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.]])"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va maintenant tester notre perceptron sur l'ensemble pr\u00e9c\u00e9dent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainset=createGaussianDataset(1,1,1,-1,-1,1,200)\n",
      "perceptron=Perceptron(0.001,10)\n",
      "\n",
      "perceptron.train(trainset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'theta' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-12-0a180903cfe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreateGaussianDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mperceptron\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-10-598f8c85d702>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, gradient_step, nb_iterations)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'theta' is not defined"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualiser la frontiere de d\u00e9cision obtenus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 3 : Tester le Perceptron\n",
      "------\n",
      "On va maintenant cr\u00e9er des ensembles de test et de train selon plusieurs distribution et tracer les courbes d'apprentissage (accuraacy) sur train et test dans le temps. Pouvez vous faire apparaitre un effet de sur-apprentissage? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pouvez vous faire apparaitre un cas ou le perceptron ne peut pas apprendre"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 4 : Kernel Trick\n",
      "-----\n",
      "On va transformer nos vecteurs d'entr\u00e9e de la mani\u00e8re suivante: $(x_1,x_2) \\rightarrow $(x_1,x_2,1)$. Apprenez le perceptron sur le nouvel ensemble et visualisez sa frontiere de d\u00e9cision. Que pouvez vous dire ? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va transformer nos vecteurs d'entr\u00e9e de la mani\u00e8re suivante: $(x_1,x_2) \\rightarrow $(x_1,x_2,1,x_1*x_1,x_2*x_2,x_1*x_2)$. Apprenez le perceptron sur le nouvel ensemble et visualisez sa frontiere de d\u00e9cision. Que pouvez vous dire ? Pourquoi observe-t-on cette fronti\u00e8re de d\u00e9cision ? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Etape 5 : UCI\n",
      "-----\n",
      "\n",
      "Plusieurs datasets sont t\u00e9l\u00e9chargeables ici:  http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/\n",
      "\n",
      "* Impl\u00e9mentez une fonction permettant de les charger\n",
      "* Impl\u00e9mnetez une fonction permettant de les \"splitter\" en train et test\n",
      "* Lancer les diff\u00e9rentes perceptrons la dessus et tracer les courbes de performance\n",
      "\n",
      "(Datasets conseill\u00e9s: sonar, jeart, breast-cancer et ionosphere)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}